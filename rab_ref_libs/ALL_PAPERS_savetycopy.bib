@InProceedings{1968_Weisfeiler_InProceedings,
  author         = {Weisfeiler, Boris and Leman, Andrei},
  title          = {The reduction of a graph to canonical form and the algebra which appears therein},
  year           = {1968},
  number         = {9},
  pages          = {12--16},
  volume         = {2},
  abstract       = {We consider an algorithm for the reduction of a given finite multigraph Γ to
canonical form. Therein the new invariant of a graph appears — the algebra A(Γ). The
study of properties of the algebra A(Γ) turns out to be helpful in solving a number of
graph-theoretic problems. We pose and discuss some conjectures on the relation between
properties of the algebra A(Γ) and the automorphism group Aut(Γ) of a graph Γ. We give
an example of undirected graph Γ whose algebra A(Γ) coincides with the group algebra of
some noncommutative group.},
  file           = {:/home/fabrice/Documents/library/papers/1968_Weisfeiler_CONF.pdf:PDF},
  journal        = {nti, Series},
  qualityassured = {qualityAssured},
  url            = {https://www.iti.zcu.cz/wl2018/pdf/wl_paper_translation.pdf},
}

@Article{1976_Ullmann_Article,
  author         = {Ullmann, Julian R.},
  journal        = {Journal of the ACM (JACM)},
  title          = {An algorithm for subgraph isomorphism},
  year           = {1976},
  month          = {jan},
  number         = {1},
  pages          = {31--42},
  volume         = {23},
  abstract       = {Subgraph isomorphism can be determined by means of a brute-force tree-search enu-
meration procedure. In this paper a new algorithm is introduced that attains efficiencyb y inferentially 
eliminatings uccessor nodes in the tree search. To assess the time actually taken by the new algomthm, 
subgraph isomorphism, chque detection, graph isomorphism, and directed graph isomorphism ex- 
periments have been carried out with random and with various nonrandom graphs.},
  doi            = {10.1145/321921.321925},
  file           = {:/home/fabrice/Documents/library/papers/1976_Ullmann_CONF.pdf:PDF},
  groups         = {AppliedGraphtheory},
  publisher      = {ACM New York, NY, USA},
  qualityassured = {qualityAssured},
  readstatus     = {read},
  url            = {https://dl.acm.org/doi/abs/10.1145/321921.321925},
}

@Article{1980_Babai_Article,
  author         = {L{\'{a}}szl{\'{o}} Babai and Paul Erdo{\H{}}s and Stanley M. Selkow},
  journal        = {{SIAM} Journal on Computing},
  title          = {{R}andom {G}raph {I}somorphism},
  year           = {1980},
  month          = {aug},
  number         = {3},
  pages          = {628--635},
  volume         = {9},
  abstract       = {SIAM J. Comput. 1980.9:628-635},
  doi            = {10.1137/0209047},
  file           = {:/home/fabrice/Documents/library/papers/1980_Babai_SIAM.pdf:PDF},
  groups         = {AppliedGraphtheory},
  keywords       = {graph,isomorphism testing,canonical labeling,random graph,naive algorithm,average-case analysis,linear time,degree sequence of a graph},
  publisher      = {SIAM},
  qualityassured = {qualityAssured},
  url            = {https://epubs.siam.org/doi/abs/10.1137/0209047?casa_token=0hkCRph-MG8AAAAA:5icBO-Cq_3yf0CfVieB2Mcw5SyRkTbMvFGWpErLTdBGAUu-p39w8_x0fFllWSA3lmq0qrSsnv39-},
}

@Book{2007_Mitchell_Book,
  author         = {Mitchell, Tom Michael and others},
  publisher      = {McGraw-hill New York},
  title          = {Machine learning},
  year           = {2007},
  volume         = {1},
  file           = {:/home/fabrice/Documents/library/papers/1983_Mitchell_BOOK.pdf:PDF},
  qualityassured = {qualityAssured},
  url            = {https://library.iitgn.ac.in/documents/library_files/2016/19032016.pdf},
}

@Article{1992_Cai_Article,
  author         = {Cai, Jin-Yi and F{\"u}rer, Martin and Immerman, Neil},
  journal        = {Combinatorica},
  title          = {An optimal lower bound on the number of variables for graph identification},
  year           = {1992},
  month          = {dec},
  number         = {4},
  pages          = {389--410},
  volume         = {12},
  doi            = {10.1007/bf01305232},
  file           = {:/home/fabrice/Documents/library/papers/1992_Cai_IEEE.pdf:PDF},
  groups         = {AppliedGraphtheory},
  publisher      = {Springer Science and Business Media {LLC}},
  qualityassured = {qualityAssured},
  readstatus     = {read},
  url            = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=e8151a322b62a37b03c105d0033c3775b00f1ee1},
}

@Article{1992_Wilkinson_Article,
  author         = {Wilkinson, Leland and others},
  journal        = {Retrieved February},
  title          = {{T}ree structured data analysis: {AID}, {CHAID} and {CART}},
  year           = {1992},
  pages          = {2008},
  volume         = {1},
  file           = {:/home/fabrice/Documents/library/papers/1992_Wilkinson_CONF.pdf:PDF},
  qualityassured = {qualityAssured},
  url            = {https://www.researchgate.net/profile/Leland-Wilkinson/publication/228698437_Tree_structured_data_analysis_AID_CHAID_and_CART/links/55e72a2a08ae21d099c148c3/Tree-structured-data-analysis-AID-CHAID-and-CART.pdf},
}

@Article{1992_Zhang_Article,
  author         = {Zhang, Kaizhong and Statman, Rick and Shasha, Dennis},
  journal        = {Information processing letters},
  title          = {On the editing distance between unordered labeled trees},
  year           = {1992},
  number         = {3},
  pages          = {133--139},
  volume         = {42},
  file           = {:/home/fabrice/Documents/library/papers/1992_Zhang_CONF.pdf:PDF},
  groups         = {AppliedGraphtheory},
  keywords       = {Computational complexity, unordered trees},
  publisher      = {Elsevier},
  qualityassured = {qualityAssured},
  url            = {https://www.sciencedirect.com/science/article/pii/002001909290136J},
}

@InProceedings{1993_Zhang_InProceedings,
  author         = {Zhang, Kaizhong},
  booktitle      = {Combinatorial Pattern Matching: 4th Annual Symposium, CPM 93 Padova, Italy, June 2--4, 1993 Proceedings 4},
  title          = {A new editing based distance between unordered labeled trees},
  year           = {1993},
  organization   = {Springer},
  pages          = {254--265},
  file           = {:/home/fabrice/Documents/library/papers/1993_Zhang_CONF.pdf:PDF},
  groups         = {AppliedGraphtheory},
  qualityassured = {qualityAssured},
  url            = {https://link.springer.com/chapter/10.1007/BFb0029810},
}

@Article{1995_LeCun_Article,
  author         = {LeCun, Yann and Bengio, Yoshua and others},
  journal        = {The handbook of brain theory and neural networks},
  title          = {Convolutional networks for images, speech, and time series},
  year           = {1995},
  number         = {10},
  pages          = {1995},
  volume         = {3361},
  file           = {:/home/fabrice/Documents/library/papers/1995_LeCun_CONF.pdf:PDF},
  groups         = {Convolutional networks},
  publisher      = {Citeseer},
  qualityassured = {qualityAssured},
  url            = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=e26cc4a1c717653f323715d751c8dea7461aa105},
}

@InProceedings{2985_Learning_InProceedings,
  author    = {Gradient-Based Learning and Applied to Document and Recognition},
  title     = {See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication},
  year      = {2985},
  publisher = {IEEE},
  file      = {:/home/fabrice/Documents/library/papers/1998_Lecun_IEEE.pdf:PDF},
}

@InProceedings{4044_intersectionkernelforimageclassification_InProceedings,
  author    = {Histogram intersection kernel for image classification},
  title     = {See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication},
  year      = {4044},
  publisher = {IEEE},
  file      = {:/home/fabrice/Documents/library/papers/2003_Barla_CONF.pdf:PDF},
}

@Article{2005_Deshpande_Article,
  author         = {Deshpande, Mukund and Kuramochi, Michihiro and Wale, Nikil and Karypis, George},
  journal        = {IEEE Transactions on Knowledge and Data Engineering},
  title          = {Frequent substructure-based approaches for classifying chemical compounds},
  year           = {2005},
  number         = {8},
  pages          = {1036--1050},
  volume         = {17},
  file           = {:/home/fabrice/Documents/library/papers/2003_Deshpande_TECH_REPORT.pdf:PDF},
  groups         = {AppliedGraphtheory},
  publisher      = {IEEE},
  qualityassured = {qualityAssured},
  url            = {https://ieeexplore.ieee.org/abstract/document/1458698/},
}

@Article{2003_Dobson_Article,
  author         = {Dobson, Paul D. and Doig, Andrew J.},
  journal        = {Journal of molecular biology},
  title          = {Distinguishing enzyme structures from non-enzymes without alignments},
  year           = {2003},
  number         = {4},
  pages          = {771--783},
  volume         = {330},
  doi            = {10.1016/S0022-2836(03)00628-4},
  file           = {:/home/fabrice/Documents/library/papers/2003_Dobson_CONF.pdf:PDF},
  keywords       = {protein function prediction; structure; enzyme; machine *Corresponding author learning; structural genomics},
  publisher      = {Elsevier},
  qualityassured = {qualityAssured},
  url            = {https://www.sciencedirect.com/science/article/pii/S0022283603006284?casa_token=IX2kOcHWpSgAAAAA:7AxKoWztPZf1e993W32gyVYDnkEoihOl359BDY2EORGTaL4EpE2tZFtd-Y_sWjzkjZkXEikscNY},
}

@InProceedings{2214_ThomasGaertner_InProceedings,
  author   = {Thomas Gärtner, Peter Flach, and Stefan Wrobel},
  title    = {LNAI 2777 - On Graph Kernels: Hardness Results and Efficient Alternatives},
  year     = {2214},
  abstract = {Learning Theory and Kernel Machines},
  file     = {:/home/fabrice/Documents/library/papers/2003_Gaertner_CONF.pdf:PDF},
}

@Misc{2003_Hsu_Misc,
  author         = {Hsu, Chih-Wei and Chang, Chih-Chung and Lin, Chih-Jen and others},
  title          = {A practical guide to support vector classification},
  year           = {2003},
  abstract       = {The support vector machine (SVM) is a popular classification technique.
However, beginners who are not familiar with SVM often get unsatisfactory
results since they miss some easy but significant steps. In this guide, we propose
a simple procedure which usually gives reasonable results.},
  file           = {:/home/fabrice/Documents/library/papers/2003_Hsu_CONF.pdf:PDF},
  groups         = {Support Vector Machines},
  publisher      = {Taipei, Taiwan},
  qualityassured = {qualityAssured},
  url            = {http://www.datascienceassn.org/sites/default/files/Practical Guide to Support Vector Classification.pdf},
}

@Article{2003_Kashima_Article,
  author         = {Hisashi Kashima and Koji Tsuda and Akihiro Inokuchi},
  title          = {Marginalized kernels between labeled graphs},
  year           = {2003},
  abstract       = {Proceedings of the Twentieth International Conference on Machine Learning},
  file           = {:/home/fabrice/Documents/library/papers/2003_Kashima_CONF.pdf:PDF},
  keywords       = {Compilation copyright ©2003, American Association for Artificial Intelligence. All rights reserved.},
  publisher      = {IEEE},
  qualityassured = {qualityAssured},
  url            = {https://pure.mpg.de/pubman/faces/ViewItemOverviewPage.jsp?itemId=item_3187440},
}

@InProceedings{2333_Nijssen_InProceedings,
  author   = {Siegfried Nijssen and Joost N. Kok},
  title    = {Efficient Discovery of Frequent Unordered Trees},
  year     = {2333},
  abstract = {Recently, an algorithm called Freqt was introduced which
enumerates all frequent induced subtrees in an ordered data tree. We
propose a new algorithm for mining unordered frequent induced sub-
trees. We show that the complexity of enumerating unordered trees is
not higher than the complexity of enumerating ordered trees; a strategy
for determining the frequency of unordered trees is introduced.},
  file     = {:/home/fabrice/Documents/library/papers/2003_Nijssen_CONF.pdf:PDF},
}

@InProceedings{2004_Horvath_InProceedings,
  author         = {Horv{\'a}th, Tam{\'a}s and G{\"a}rtner, Thomas and Wrobel, Stefan},
  booktitle      = {Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining},
  title          = {Cyclic pattern kernels for predictive graph mining},
  year           = {2004},
  pages          = {158--167},
  abstract       = {With applications in biology, the world-wide web, and sev-
eral other areas, mining of graph-structured objects has re-
ceived signiﬁcant interest recently. One of the major re-
search directions in this ﬁeld is concerned with predictive
data mining in graph databases where each instance is repre-
sented by a graph. Some of the proposed approaches for this
task rely on the excellent classiﬁcation performance of sup-
port vector machines. To control the computational cost of
these approaches, the underlying kernel functions are based
on frequent patterns. In contrast to these approaches, we
propose a kernel function based on a natural set of cyclic and
tree patterns independent of their frequency, and discuss its
computational aspects. To practically demonstrate the ef-
fectiveness of our approach, we use the popular NCI-HIV
molecule dataset. Our experimental results show that cyclic
pattern kernels can be computed quickly and oﬀer predic-
tive performance superior to recent graph kernels based on
frequent patterns.},
  file           = {:/home/fabrice/Documents/library/papers/2004_Horvath_KDD.pdf:PDF},
  groups         = {AppliedGraphtheory},
  keywords       = {tured graphs while being efficient enough to be applied to},
  qualityassured = {qualityAssured},
  url            = {https://dl.acm.org/doi/abs/10.1145/1014052.1014072?casa_token=6MMEvYGG5I0AAAAA:iIfwiPhtku7VJZ3vHUOCYCDlV5xvcCMDmzDzH-nJTIj3fyfHnuzQK4gXf7quu25WFfQi8YqnFeZq3w},
}

@InProceedings{2004_Mahe_InProceedings,
  author         = {Mah{\'e}, Pierre and Ueda, Nobuhisa and Akutsu, Tatsuya and Perret, Jean-Luc and Vert, Jean-Philippe},
  booktitle      = {Proceedings of the twenty-first international conference on Machine learning},
  title          = {Extensions of marginalized graph kernels},
  year           = {2004},
  pages          = {70},
  publisher      = {{ACM} Press},
  abstract       = {tial drugs, require the analysis, comparison, and clas-
sification of these graphs. Among the many different},
  doi            = {10.1145/1015330.1015446},
  file           = {:/home/fabrice/Documents/library/papers/2004_Mahe_ICML.pdf:PDF},
  groups         = {AppliedGraphtheory},
  qualityassured = {qualityAssured},
}

@Article{2005_Bille_Article,
  author         = {Bille, Philip},
  journal        = {Theoretical computer science},
  title          = {A survey on tree edit distance and related problems},
  year           = {2005},
  month          = {jun},
  number         = {1-3},
  pages          = {217--239},
  volume         = {337},
  doi            = {10.1016/j.tcs.2004.12.030},
  file           = {:/home/fabrice/Documents/library/papers/2005_Bille_TCS.pdf:PDF},
  keywords       = {Tree matching; Tree edit distance; Tree alignment; Tree inclusion},
  publisher      = {Elsevier},
  qualityassured = {qualityAssured},
}

@Article{2005_Borgwardt_Article,
  author         = {K. M. Borgwardt and C. S. Ong and S. Schonauer and S. V. N. Vishwanathan and A. J. Smola and H.-P. Kriegel},
  journal        = {Bioinformatics},
  title          = {Protein function prediction via graph kernels},
  year           = {2005},
  month          = {jun},
  number         = {Suppl 1},
  pages          = {i47--i56},
  volume         = {21},
  abstract       = {known function is consequently the basis of current function
Motivation: Computational approaches to protein function prediction (Whisstock and Lesk, 2003). A newly discovered
prediction infer protein function by finding proteins with sim- protein is predicted to exert the same function as the most
ilar sequence, structure, surface clefts, chemical properties, similar proteins in a database of known proteins. This simil-
amino acid motifs, interaction partners or phylogenetic pro- arity among proteins can be defined in a multitude of ways:
files. We present a new approach that combines sequential, two proteins can be regarded to be similar, if their sequences
structural and chemical information into one graph model of align well [e.g. PSI-BLAST (Altschul et al., 1997)], if their
proteins. We predict functional class membership of enzymes structures match well [e.g. DALI (Holm and Sander, 1996)],
and non-enzymes using graph kernels and support vector if both have common surface clefts or bindings sites [e.g.
machine classification on these protein graphs. CASTp (Binkowski et al., 2003)], similar chemical fea-
Results: Our graph model, derivable from protein sequence tures or common interaction partners [e.g. DIP (Xenarios
and structure only, is competitive with vector models that et al., 2002)], if both contain certain motifs of amino acids
require additional protein information, such as the size of (AAs) [e.g. Evolutionary Trace (Yao et al., 2003)] or if both
surface pockets. If we include this extra information into our appear in the same range of species (Pellegrini et al., 1999).
graph model, our classifier yields significantly higher accuracy An armada of protein function prediction systems that meas-
levels than the vector models. Hyperkernels allow us to select ure protein similarity by one of the conditions above has been
and to optimally combine the most relevant node attributes in developed. Each of these conditions is based on a biological
our protein graphs. We have laid the foundation for a protein hypothesis; e.g. structural similarity implies that two proteins
function prediction system that integrates protein information could share a common ancestor and that they both could per-
from various sources efficiently and effectively. form the same function as this common ancestor (Bartlett
Availability: More information available via www.dbs.ifi.lmu. et al., 2003).
de/Mitarbeiter/borgwardt.html. These assumptions are not universally valid. Hegyi and
Contact: borgwardt@dbs.ifi.lmu.de Gerstein (1999) showed that proteins with similar function},
  doi            = {10.1093/bioinformatics/bti1007},
  file           = {:/home/fabrice/Documents/library/papers/2005_Borgwardt_CONF.pdf:PDF},
  groups         = {AppliedGraphtheory},
  publisher      = {Oxford University Press ({OUP})},
  qualityassured = {qualityAssured},
}

@InProceedings{8053_Borgwardt_InProceedings,
  author   = {Karsten M. Borgwardt and Hans-Peter Kriegel and Institute for Computer and Science},
  title    = {Shortest-path kernels on graphs},
  year     = {8053},
  abstract = {this purpose. However, kernels on these substructures are
either computationally expensive, sometimes even NP-hard},
  file     = {:/home/fabrice/Documents/library/papers/2005_Borgwardt_IEEE.pdf:PDF},
}

@InProceedings{4186_Histogram_InProceedings,
  author    = {Generalized Histogram and Intersection Kernel and for Image and Recognition},
  title     = {See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication},
  year      = {4186},
  publisher = {IEEE},
  file      = {:/home/fabrice/Documents/library/papers/2005_Boughorbel_IEEE.pdf:PDF},
}

@InProceedings{2213_Assignment_InProceedings,
  author = {Optimal Assignment and Kernels for Attributed and Molecular Graphs},
  title  = {See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication},
  year   = {2213},
  file   = {:/home/fabrice/Documents/library/papers/2005_Froehlich_ICML.pdf:PDF},
}

@InProceedings{2005_Yang_InProceedings,
  author         = {Yang, Rui and Kalnis, Panos and Tung, Anthony K. H.},
  booktitle      = {Proceedings of the 2005 ACM SIGMOD international conference on Management of data},
  title          = {Similarity evaluation on tree-structured data},
  year           = {2005},
  pages          = {754--765},
  abstract       = {and the linear representation of data. They allow the expres-},
  file           = {:/home/fabrice/Documents/library/papers/2005_Yang_CONF.pdf:PDF},
  groups         = {AppliedGraphtheory},
  qualityassured = {qualityAssured},
  url            = {https://dl.acm.org/doi/abs/10.1145/1066157.1066243?casa_token=ed2_pSRWMxUAAAAA:z_qjxyDebnISDdoq1tdJcSlWjus9dcqTD3_J3lW05cqpOcpX6PcvWwEcCZuB7S6jHaUcf0ttms4wVw},
}

@Book{2006_Bishop_Book,
  author         = {Bishop, Christopher M. and Nasrabadi, Nasser M.},
  publisher      = {Springer},
  title          = {Pattern recognition and machine learning},
  year           = {2006},
  number         = {4},
  volume         = {4},
  file           = {:/home/fabrice/Documents/library/papers/2006_Bishop_BOOK.pdf:PDF},
  qualityassured = {qualityAssured},
  url            = {https://link.springer.com/book/9780387310732},
}

@PhdThesis{2007_Borgwardt_InProceedings,
  author         = {Karsten Michael Borgwardt},
  title          = {{G}raph {K}ernels},
  year           = {2007},
  file           = {:/home/fabrice/Documents/library/papers/2007_Borgwardt_BOOK.pdf:PDF},
  groups         = {AppliedGraphtheory},
  qualityassured = {qualityAssured},
}

@InProceedings{4260_Classification_InProceedings,
  author    = {Image Classification and with Segmentation and Graph Kernels},
  title     = {See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication},
  year      = {4260},
  publisher = {IEEE},
  file      = {:/home/fabrice/Documents/library/papers/2007_Harchaoui_IEEE.pdf:PDF},
}

@Article{2007_Wale_Article,
  author         = {Nikil Wale and Ian A. Watson and George Karypis},
  journal        = {Knowledge and Information Systems},
  title          = {Comparison of descriptor spaces for chemical compound retrieval and classification},
  year           = {2007},
  month          = {aug},
  number         = {3},
  pages          = {347--375},
  volume         = {14},
  abstract       = {In recent years the development of computational techniques that build models
to correctly assign chemical compounds to various classes or to retrieve potential drug-like
compounds has been an active area of research. Many of the best-performing techniques for
these tasks utilize a descriptor-based representation of the compound that captures various
aspects of the underlying molecular graph’s topology. In this paper we compare five dif-
ferent set of descriptors that are currently used for chemical compound classification. We
also introduce four different descriptors derived from all connected fragments present in the
molecular graphs primarily for the purpose of comparing them to the currently used des-
criptor spaces and analyzing what properties of descriptor spaces are helpful in providing
effective representation for molecular graphs. In addition, we introduce an extension to exis-
ting vector-based kernel functions to take into account the length of the fragments present
in the descriptors. We experimentally evaluate the performance of the previously introduced
and the new descriptors in the context of SVM-based classification and ranked-retrieval on
28 classification and retrieval problems derived from 18 datasets. Our experiments show that
for both of these tasks, two of the four descriptors introduced in this paper along with the
extended connectivity fingerprint based descriptors consistently and statistically outperform
previously developed schemes based on the widely used fingerprint- and Maccs keys-based
descriptors, as well as recently introduced descriptors obtained by mining and analyzing the
structure of the molecular graphs.},
  doi            = {10.1007/s10115-007-0103-5},
  file           = {:/home/fabrice/Documents/library/papers/2007_Wale_CONF.pdf:PDF},
  publisher      = {Springer Science and Business Media {LLC}},
  qualityassured = {qualityAssured},
}

@Article{2008_Hofmann_Article,
  author         = {Thomas Hofmann and Bernhard Schölkopf and Alexander J. Smola},
  journal        = {The Annals of Statistics},
  title          = {Kernel methods in machine learning},
  year           = {2008},
  month          = {jun},
  number         = {3},
  volume         = {36},
  abstract       = {The Annals of Statistics, 2008, Vol.36, No.3, 1171-1220},
  doi            = {10.1214/009053607000000677},
  file           = {:/home/fabrice/Documents/library/papers/2008_Hofmann_CONF.pdf:PDF},
  publisher      = {Institute of Mathematical Statistics},
  qualityassured = {qualityAssured},
  url            = {https://projecteuclid.org/journals/annals-of-statistics/volume-36/issue-3/Kernel-methods-in-machine-learning/10.1214/009053607000000677.full},
}

@InProceedings{2008_Kondor_InProceedings,
  author         = {Risi Kondor and Karsten M. Borgwardt},
  booktitle      = {Proceedings of the 25th international conference on Machine learning - {ICML} {\textquotesingle}08},
  title          = {{T}he {S}kew {S}pectrum of {G}raphs},
  year           = {2008},
  publisher      = {{ACM} Press},
  abstract       = {Given a graph G, the two main lines of research that
have emerged to address the above problem focus re-},
  doi            = {10.1145/1390156.1390219},
  file           = {:/home/fabrice/Documents/library/papers/2008_Kondor_ICML.pdf:PDF},
  groups         = {AppliedGraphtheory},
  qualityassured = {qualityAssured},
}

@Article{2008_Mahe_Article,
  author         = {Pierre Mah{\'{e}} and Jean-Philippe Vert},
  journal        = {Machine Learning},
  title          = {Graph kernels based on tree patterns for molecules},
  year           = {2008},
  month          = {oct},
  number         = {1},
  pages          = {3--35},
  volume         = {75},
  abstract       = {Motivated by chemical applications, we revisit and extend a family of positive
definite kernels for graphs based on the detection of common subtrees, initially proposed by
Ramon and Gärtner (Proceedings of the first international workshop on mining graphs, trees
and sequences, pp. 65–74, 2003). We propose new kernels with a parameter to control the
complexity of the subtrees used as features to represent the graphs. This parameter allows to
smoothly interpolate between classical graph kernels based on the count of common walks,
on the one hand, and kernels that emphasize the detection of large common subtrees, on the
other hand. We also propose two modular extensions to this formulation. The first extension
increases the number of subtrees that define the feature space, and the second one removes
noisy features from the graph representations. We validate experimentally these new kernels
on problems of toxicity and anti-cancer activity prediction for small molecules with support
vector machines.},
  doi            = {10.1007/s10994-008-5086-2},
  file           = {:/home/fabrice/Documents/library/papers/2008_Mahé_CONF.pdf:PDF},
  groups         = {AppliedGraphtheory},
  keywords       = {Graph kernels · Support vector machines · Chemoinformatics},
  publisher      = {Springer Science and Business Media {LLC}},
  qualityassured = {qualityAssured},
}

@InProceedings{2009_Kondor_InProceedings,
  author         = {Risi Kondor and Nino Shervashidze and Karsten M. Borgwardt},
  booktitle      = {Proceedings of the 26th Annual International Conference on Machine Learning - {ICML} {\textquotesingle}09},
  title          = {The graphlet spectrum},
  year           = {2009},
  publisher      = {{ACM} Press},
  abstract       = {In this paper, we overcome these two limitations by},
  doi            = {10.1145/1553374.1553443},
  file           = {:/home/fabrice/Documents/library/papers/2009_Kondor_ICML.pdf:PDF},
  groups         = {AppliedGraphtheory},
  qualityassured = {qualityAssured},
}

@Article{2008_Kulis_Article,
  author         = {Brian Kulis and Sugato Basu and Inderjit Dhillon and Raymond Mooney},
  journal        = {Machine Learning},
  title          = {Semi-supervised graph clustering: a kernel approach},
  year           = {2008},
  month          = {sep},
  number         = {1},
  pages          = {1--22},
  volume         = {74},
  abstract       = {Semi-supervised clustering algorithms aim to improve clustering results using
limited supervision. The supervision is generally given as pairwise constraints; such con-
straints are natural for graphs, yet most semi-supervised clustering algorithms are designed
for data represented as vectors. In this paper, we unify vector-based and graph-based ap-
proaches. We first show that a recently-proposed objective function for semi-supervised
clustering based on Hidden Markov Random Fields, with squared Euclidean distance and
a certain class of constraint penalty functions, can be expressed as a special case of the
weighted kernel k-means objective (Dhillon et al., in Proceedings of the 10th International
Conference on Knowledge Discovery and Data Mining, 2004a). A recent theoretical con-
nection between weighted kernel k-means and several graph clustering objectives enables
us to perform semi-supervised clustering of data given either as vectors or as a graph. For
graph data, this result leads to algorithms for optimizing several new semi-supervised graph
clustering objectives. For vector data, the kernel approach also enables us to find clusters
with non-linear boundaries in the input data space. Furthermore, we show that recent work
on spectral learning (Kamvar et al., in Proceedings of the 17th International Joint Confer-
ence on Artificial Intelligence, 2003) may be viewed as a special case of our formulation.
We empirically show that our algorithm is able to outperform current state-of-the-art semi-
supervised algorithms on both vector-based and graph-based data sets.},
  doi            = {10.1007/s10994-008-5084-4},
  file           = {:/home/fabrice/Documents/library/papers/2009_Kulis_SpringerMachineLearning.pdf:PDF},
  keywords       = {Semi-supervised clustering · Kernel k-means · Graph clustering · Spectral learning},
  publisher      = {Springer Science and Business Media {LLC}},
  qualityassured = {qualityAssured},
}

@Article{2009_FrancoScarselli_Article,
  author         = {Franco Scarselli and Marco Gori and Ah Chung Tsoi and Markus Hagenbuchner and Gabriele Monfardini},
  journal        = {{IEEE} Transactions on Neural Networks},
  title          = {{T}he {G}raph {N}eural {N}etwork {M}odel},
  year           = {2009},
  month          = {jan},
  number         = {1},
  pages          = {61--80},
  volume         = {20},
  doi            = {10.1109/tnn.2008.2005605},
  file           = {:/home/fabrice/Documents/library/papers/2009_Scarselli_IEEE.pdf:PDF},
  groups         = {Graph Neural Networks, AppliedGraphtheory},
  publisher      = {Institute of Electrical and Electronics Engineers ({IEEE})},
  qualityassured = {qualityAssured},
}

@InProceedings{2009_NinoShervashidze_InProceedings,
  author         = {Nino Shervashidze, Karsten M. Borgwardt},
  title          = {Fast subtree kernels on graphs},
  year           = {2009},
  volume         = {22},
  abstract       = {Neural Information Processing Systems http://nips.cc/},
  file           = {:/home/fabrice/Documents/library/papers/2009_Shervashidze_NIPS.pdf:PDF},
  groups         = {AppliedGraphtheory},
  journal        = {Advances in neural information processing systems},
  qualityassured = {qualityAssured},
  readstatus     = {read},
  url            = {https://proceedings.neurips.cc/paper/3813-fast-subtree-kernels-on-graphs},
}

@InProceedings{2207_tmatsui_InProceedings,
  author = {tmatsui},
  title  = {Microsoft Word - icassp_tomoko_081002.docx},
  year   = {2207},
  file   = {:/home/fabrice/Documents/library/papers/2009_Vert_IEEE.pdf:PDF},
}

@InProceedings{2010_FabrizioCosta_InProceedings,
  author         = {Fabrizio Costa, Kurt De Grave},
  title          = {{F}ast {N}eighborhood {S}ubgraph {P}airwise {D}istance {K}ernel},
  year           = {2010},
  abstract       = {performance (Ben-David et al., 2002). Possible reme-},
  file           = {:/home/fabrice/Documents/library/papers/2010_Costa_ICML.pdf:PDF},
  groups         = {Graph Kernels},
  keywords       = {graph kernel, chemoinformatics, molecular graph},
  qualityassured = {qualityAssured},
}

@InProceedings{2011_Bonneel_InProceedings,
  author         = {Nicolas Bonneel and Michiel van de Panne and Sylvain Paris and Wolfgang Heidrich},
  title          = {{D}isplacement {I}nterpolation {U}sing {L}agrangian {M}ass {T}ransport},
  year           = {2011},
  abstract       = {1 Introduction},
  file           = {:/home/fabrice/Documents/library/papers/2011_Bonneel_SIGGRAPH.pdf:PDF},
  keywords       = {displacement interpolation, mass transport rection is, subjectively speaking, better defined as having a single},
  qualityassured = {qualityAssured},
}

@Article{2011_Chang_Article,
  author         = {Chih-Chung Chang and Chih-Jen Lin},
  journal        = {{ACM} Transactions on Intelligent Systems and Technology},
  title          = {{LIBSVM}},
  year           = {2011},
  month          = {apr},
  number         = {3},
  pages          = {1--27},
  volume         = {2},
  doi            = {10.1145/1961189.1961199},
  file           = {:/home/fabrice/Documents/library/papers/2011_Chang_ACM.pdf:PDF},
  publisher      = {Association for Computing Machinery ({ACM})},
  qualityassured = {qualityAssured},
}

@Article{2011_Shervashidze_Article,
  author         = {Shervashidze, Nino and Schweitzer, Pascal and Van Leeuwen, Erik Jan and Mehlhorn, Kurt and Borgwardt, Karsten M.},
  journal        = {Journal of Machine Learning Research},
  title          = {Weisfeiler-lehman graph kernels.},
  year           = {2011},
  number         = {9},
  volume         = {12},
  file           = {:/home/fabrice/Documents/library/papers/2011_Shervashidze_JMLR.pdf:PDF},
  groups         = {Graph Kernels},
  keywords       = {graph kernels, graph classification, similarity measures for graphs, Weisfeiler-Lehman algorithm},
  qualityassured = {qualityAssured},
  readstatus     = {read},
  url            = {https://www.jmlr.org/papers/volume12/shervashidze11a/shervashidze11a.pdf},
}

@Article{2011_Wang_Article,
  author         = {Wang, Haizhou and Song, Mingzhou},
  journal        = {The R journal},
  title          = {Ckmeans. 1d. dp: optimal k-means clustering in one dimension by dynamic programming},
  year           = {2011},
  number         = {2},
  pages          = {29},
  volume         = {3},
  file           = {:/home/fabrice/Documents/library/papers/2011_Wang_CONF.pdf:PDF},
  publisher      = {NIH Public Access},
  qualityassured = {qualityAssured},
  url            = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5148156/},
}

@Article{2012_Jovanovic_Article,
  author         = {Irena Jovanovi{\'{c}} and Zoran Stani{\'{c}}},
  journal        = {Linear Algebra and its Applications},
  title          = {Spectral distances of graphs},
  year           = {2012},
  month          = {mar},
  number         = {5},
  pages          = {1425--1435},
  volume         = {436},
  abstract       = {Linear Algebra and Its Applications, 436 (2012) 1425-1435. doi:10.1016/j.laa.2011.08.019},
  doi            = {10.1016/j.laa.2011.08.019},
  file           = {:/home/fabrice/Documents/library/papers/2012_Jovanovic_ELSEVIER.pdf:PDF},
  groups         = {AppliedGraphtheory},
  keywords       = {Spectral distance, Adjacency matrix, Graph energy, Cospectrality measure, Spectral diameter},
  publisher      = {Elsevier {BV}},
  qualityassured = {qualityAssured},
}

@InProceedings{2012_NilsKriege_InProceedings,
  author         = {Nils Kriege, Petra Mutzel},
  title          = {{S}ubgraph {M}atching {K}ernels for {A}ttributed {G}raphs},
  year           = {2012},
  abstract       = {Proceedings of the International Conference on Machine Learning 2010},
  eprint         = {1206.6483},
  file           = {:/home/fabrice/Documents/library/papers/2012_Kriege_CONF.pdf:PDF},
  keywords       = {graph matching, common subgraph, graph kernel, machine learning, ICML},
  qualityassured = {qualityAssured},
}

@Article{2013_Bruna_Article,
  author  = {Bruna, Joan and Zaremba, Wojciech and Szlam, Arthur and LeCun, Yann},
  journal = {arXiv preprint arXiv:1312.6203},
  title   = {Spectral networks and locally connected networks on graphs},
  year    = {2013},
  file    = {:/home/fabrice/Documents/library/papers/2013_Bruna_CONF.pdf:PDF},
  url     = {https://arxiv.org/abs/1312.6203},
}

@Article{2013_Oury_Article,
  author    = {Nicolas Oury and Michael Pedersen and Rasmus Petersen},
  journal   = {Electronic Proceedings in Theoretical Computer Science},
  title     = {Canonical Labelling of Site Graphs},
  year      = {2013},
  month     = {jun},
  pages     = {13--28},
  volume    = {116},
  doi       = {10.4204/eptcs.116.3},
  file      = {:/home/fabrice/Documents/library/papers/2013_Oury_EPTCS.pdf:PDF},
  publisher = {Open Publishing Association},
}

@Article{2014_Wang_Article,
  author    = {Wang, Zhe and Xue, Xiangyang},
  journal   = {Support vector machines applications},
  title     = {Multi-class support vector machine},
  year      = {2014},
  pages     = {23--48},
  abstract  = {Support vector machine (SVM) was initially designed for binary
classification. To extend SVM to the multi-class scenario, a number of classification
models were proposed such as the one by Crammer and Singer (J Mach Learn Res
2:265–292, 2001). However, the number of variables in Crammer and Singer’s dual
problem is the product of the number of samples (l) by the number of classes
(k), which produces a large computational complexity. This chapter sorts the
existing classical techniques for multi-class SVM into the indirect and direct ones
and further gives the comparison for them in terms of theory and experiments.
Especially, this chapter exhibits a new Simplified Multi-class SVM (SimMSVM)
that reduces the size of the resulting dual problem from l × k to l by introducing
a relaxed classification error bound. The experimental discussion demonstrates
that the SimMSVM approach can greatly speed up the training process, while
maintaining a competitive classification accuracy.},
  doi       = {10.1007/978-3-319-02300-7__2,},
  file      = {:/home/fabrice/Documents/library/papers/2014_Wang_BOOK.pdf:PDF},
  publisher = {Springer},
  url       = {https://link.springer.com/chapter/10.1007/978-3-319-02300-7_2},
}

@InProceedings{2014_Xu_InProceedings,
  author = {Hangjun Xu and †},
  title  = {An Algorithm for Comparing Similarity Between Two Trees: Edit Distance with Gaps},
  year   = {2014},
  file   = {:/home/fabrice/Documents/library/papers/2014_Xu_CONF.pdf:PDF},
}

@Article{2015_Duvenaud_Article,
  author  = {Duvenaud, David K. and Maclaurin, Dougal and Iparraguirre, Jorge and Bombarell, Rafael and Hirzel, Timothy and Aspuru-Guzik, Al{\'a}n and Adams, Ryan P.},
  journal = {Advances in neural information processing systems},
  title   = {Convolutional networks on graphs for learning molecular fingerprints},
  year    = {2015},
  volume  = {28},
  file    = {:/home/fabrice/Documents/library/papers/2015_Duvenaud_NIPS.pdf:PDF},
  url     = {https://proceedings.neurips.cc/paper/2015/hash/f9be311e65d81a9ad8150a60844bb94c-Abstract.html},
}

@InProceedings{2015_Feragen_InProceedings,
  author    = {Aasa Feragen, Francois Lauze, Soren Hauberg},
  booktitle = {2015 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
  title     = {Geodesic exponential kernels: When curvature and linearity conflict},
  year      = {2015},
  month     = {jun},
  publisher = {{IEEE}},
  abstract  = {2015 IEEE Conference on Computer Vision and Pattern Recognition},
  doi       = {10.1109/cvpr.2015.7298922},
  file      = {:/home/fabrice/Documents/library/papers/2015_Feragen_IEEE.pdf:PDF},
}

@Article{2015_Xu_Article,
  author  = {Xu, Hangjun},
  journal = {arXiv preprint arXiv:1508.03381},
  title   = {An algorithm for comparing similarity between two trees},
  year    = {2015},
  file    = {:/home/fabrice/Documents/library/papers/2015_Xu_THESIS.pdf:PDF},
  url     = {https://arxiv.org/abs/1508.03381},
}

@InProceedings{2016_Battaglia_InProceedings,
  author   = {Peter Battaglia, Razvan Pascanu, Matthew Lai, Danilo Jimenez Rezende, koray kavukcuoglu},
  title    = {Interaction Networks for Learning about Objects, Relations and Physics},
  year     = {2016},
  abstract = {Neural Information Processing Systems http://nips.cc/},
  eprint   = {1612.00222},
  file     = {:/home/fabrice/Documents/library/papers/2016_Battaglia_NIPS.pdf:PDF},
}

@InProceedings{2016_Defferrard_InProceedings,
  author   = {Michaël Defferrard, Xavier Bresson, Pierre Vandergheynst},
  title    = {Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering},
  year     = {2016},
  abstract = {Neural Information Processing Systems http://nips.cc/},
  eprint   = {1606.09375},
  file     = {:/home/fabrice/Documents/library/papers/2016_Defferrard_NIPS.pdf:PDF},
}

@Article{2016_Kriege_Article,
  author  = {Kriege, Nils M. and Giscard, Pierre-Louis and Wilson, Richard},
  journal = {Advances in neural information processing systems},
  title   = {On valid optimal assignment kernels and applications to graph classification},
  year    = {2016},
  volume  = {29},
  file    = {:/home/fabrice/Documents/library/papers/2016_Kriege_NIPS.pdf:PDF},
  url     = {https://proceedings.neurips.cc/paper/2016/hash/0efe32849d230d7f53049ddc4a4b0c60-Abstract.html},
}

@Article{2017_Bresson_Article,
  author  = {Bresson, Xavier and Laurent, Thomas},
  journal = {arXiv preprint arXiv:1711.07553},
  title   = {Residual gated graph convnets},
  year    = {2017},
  file    = {:/home/fabrice/Documents/library/papers/2017_Bresson_CONF.pdf:PDF},
  url     = {https://arxiv.org/abs/1711.07553},
}

@InProceedings{2017_Gilmer_InProceedings,
  author   = {Justin Gilmer, Samuel S. Schoenholz, Patrick F. Riley, Oriol Vinyals, George E. Dahl},
  title    = {Neural Message Passing for Quantum Chemistry},
  year     = {2017},
  abstract = {Proceedings of the International Conference on Machine Learning 2017},
  eprint   = {1704.01212},
  file     = {:/home/fabrice/Documents/library/papers/2017_Gilmer_PMLR.pdf:PDF},
  keywords = {deep learning, chemistry, DFT},
}

@Article{2017_Griffa_Article,
  author    = {Alessandra Griffa and Benjamin Ricaud and Kirell Benzi and Xavier Bresson and Alessandro Daducci and Pierre Vandergheynst and Jean-Philippe Thiran and Patric Hagmann},
  journal   = {{NeuroImage}},
  title     = {Transient networks of spatio-temporal connectivity map communication pathways in brain functional systems},
  year      = {2017},
  month     = {jul},
  pages     = {490--502},
  volume    = {155},
  abstract  = {NeuroImage, 155 (2017) 490-502. doi:10.1016/j.neuroimage.2017.04.015},
  doi       = {10.1016/j.neuroimage.2017.04.015},
  file      = {:/home/fabrice/Documents/library/papers/2017_Griffa.pdf:PDF},
  keywords  = {Resting-state fMRI, Diffusion MRI, Brain connectivity, Multilayer network, Temporal network, Brain dynamics, Point-process, Communication-through-coherence, Spatio-temporal connectome},
  publisher = {Elsevier {BV}},
}

@InProceedings{2017_Hamilton_InProceedings,
  author = {William L. Hamilton and Rex Ying and Jure Leskovec and wleif@stanford.edu rexying@stanford.edu jure@cs.stanford.edu},
  title  = {Inductive Representation Learning on Large Graphs},
  year   = {2017},
  eprint = {1706.02216},
  file   = {:/home/fabrice/Documents/library/papers/2017_Hamilton_NIPS.pdf:PDF},
}

@Article{2017_Marcheggiani_Article,
  author  = {Marcheggiani, Diego and Titov, Ivan},
  journal = {arXiv preprint arXiv:1703.04826},
  title   = {Encoding sentences with graph convolutional networks for semantic role labeling},
  year    = {2017},
  doi     = {10.18653/v1/d17-1159},
  file    = {:/home/fabrice/Documents/library/papers/2017_Marcheggiani_CONF.pdf:PDF},
  url     = {https://arxiv.org/abs/1703.04826},
}

@InProceedings{2017_Monti_InProceedings,
  author   = {Federico Monti, Michael Bronstein, Xavier Bresson},
  title    = {Geometric Matrix Completion with Recurrent Multi-Graph Neural Networks},
  year     = {2017},
  abstract = {Neural Information Processing Systems http://nips.cc/},
  eprint   = {1704.06803},
  file     = {:/home/fabrice/Documents/library/papers/2017_Monti_CONF.pdf:PDF},
}

@InProceedings{2018_ATTENTION_InProceedings,
  author = {GRAPH ATTENTION and NETWORKS},
  title  = {Published as a conference paper at ICLR},
  year   = {2018},
  file   = {:/home/fabrice/Documents/library/papers/2017_Velickovic_ICLR.pdf:PDF},
}

@InProceedings{2018_Welke_InProceedings,
  author    = {Pascal Welke},
  title     = {Probabilistic frequent subtrees for efficient graph classification and retrieval},
  year      = {2018},
  month     = {nov},
  number    = {11},
  pages     = {1847--1873},
  publisher = {Springer Science and Business Media {LLC}},
  volume    = {107},
  abstract  = {Machine Learning, doi:10.1007/s10994-017-5688-7},
  doi       = {10.1007/s10994-017-5688-7},
  file      = {:/home/fabrice/Documents/library/papers/2017_Welke_CONF.pdf:PDF},
  journal   = {Machine Learning},
  keywords  = {Pattern mining,Frequent subgraph mining,Frequent subtree mining,Probabilistic subtrees,Efficient embedding computation,Min-hashing},
}

@Article{2018_Gera_Article,
  author    = {Ralucca Gera and L. Alonso and Brian Crawford and Jeffrey House and J. A. Mendez-Bermudez and Thomas Knuth and Ryan Miller},
  journal   = {Applied Network Science},
  title     = {Identifying network structure similarity using spectral graph theory},
  year      = {2018},
  month     = {jan},
  number    = {1},
  volume    = {3},
  abstract  = {Appl Netw Sci, doi:10.1007/s41109-017-0042-3},
  doi       = {10.1007/s41109-017-0042-3},
  file      = {:/home/fabrice/Documents/library/papers/2018_Gera_Springer.pdf:PDF},
  keywords  = {Network topology, Graph comparison metrics, Laplacian, Eigenvalue distribution, Kolmogorov-Smirnov test},
  publisher = {Springer Science and Business Media {LLC}},
}

@InProceedings{2019_Lenssen_InProceedings,
  author   = {Jan Eric Lenssen and Gaurav Rattan and Martin Grohe and 1TU Dortmund and University},
  title    = {Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks Christopher Morris1, Martin Ritzert2, Matthias Fey1, William L. Hamilton},
  year     = {2019},
  abstract = {in its neighborhood, and the final feature representation of
a graph is the histogram of the resulting node colors. By},
  file     = {:/home/fabrice/Documents/library/papers/2018_Morris_AAAI.pdf:PDF},
}

@Article{2008_Vert_Article,
  author         = {Vert, Jean-Philippe},
  journal        = {arXiv preprint arXiv:0801.4061},
  title          = {The optimal assignment kernel is not positive definite},
  year           = {2008},
  file           = {:/home/fabrice/Documents/library/papers/2018_Vert_CONF.pdf:PDF},
  groups         = {AppliedGraphtheory},
  qualityassured = {qualityAssured},
  url            = {https://arxiv.org/abs/0801.4061},
}

@InProceedings{2019_POWERFUL_InProceedings,
  author = {HOW POWERFUL and ARE GRAPH and NEURAL NETWORKS},
  title  = {Published as a conference paper at ICLR},
  year   = {2019},
  file   = {:/home/fabrice/Documents/library/papers/2018_Xu_CONF.pdf:PDF},
}

@InProceedings{2018_Ying*_InProceedings,
  author   = {Rex Ying*, Ruining He*, Kaifeng Chen*, Pong Eksombatchai*, William L. Hamilton, Jure Leskovec*},
  title    = {Graph Convolutional Neural Networks for Web-Scale Recommender Systems},
  year     = {2018},
  abstract = {[9, 12]. The representations learned using deep models can be used},
  doi      = {10.1145/3219819.3219890},
  file     = {:/home/fabrice/Documents/library/papers/2018_Ying_KDD.pdf:PDF},
}

@InProceedings{2019_Chen_InProceedings,
  author   = {Zhengdao Chen, Soledad Villar, Lei Chen, Joan Bruna},
  title    = {On the equivalence between graph isomorphism testing and function approximation with GNNs},
  year     = {2019},
  abstract = {Neural Information Processing Systems http://nips.cc/},
  eprint   = {1905.12560},
  file     = {:/home/fabrice/Documents/library/papers/2019_Chen_NIPS.pdf:PDF},
}

@Article{2019_Ivanov_Article,
  author  = {Ivanov, Sergei and Sviridov, Sergei and Burnaev, Evgeny},
  journal = {arXiv preprint arXiv:1910.12091},
  title   = {Understanding isomorphism bias in graph data sets},
  year    = {2019},
  eprint  = {1910.12091},
  file    = {:/home/fabrice/Documents/library/papers/2019_Ivanov_CONF.pdf:PDF},
}

@InProceedings{2019_Lahn_InProceedings,
  author   = {Nathaniel Lahn, Deepika Mulchandani, Sharath Raghvendra},
  title    = {A Graph Theoretic Additive Approximation of Optimal Transport},
  year     = {2019},
  abstract = {Neural Information Processing Systems http://nips.cc/},
  eprint   = {1905.11830},
  file     = {:/home/fabrice/Documents/library/papers/2019_Lahn_CONF.pdf:PDF},
}

@InProceedings{1902_Yamada_InProceedings,
  author         = {Tam Le† Makoto Yamada and † Kenji Fukumizu and † Marco Cuturi},
  title          = {{T}ree-{S}liced {V}ariants of {W}asserstein {D}istances},
  year           = {1902},
  eprint         = {1902.00342},
  file           = {:/home/fabrice/Documents/library/papers/2019_Le_NIPS.pdf:PDF},
  groups         = {AppliedGraphtheory},
  qualityassured = {qualityAssured},
}

@InProceedings{2019_Petric_InProceedings,
  author = {Hermina Petric and Maretic Mireille and EL Gheche and Ecole Polytechnique and Fédérale de Lausanne and Ecole Polytechnique and Fédérale de Lausanne},
  title  = {GOT: An Optimal Transport framework for Graph comparison},
  year   = {2019},
  file   = {:/home/fabrice/Documents/library/papers/2019_Maretic_CONF.pdf:PDF},
}

@InProceedings{2019_Maron_InProceedings,
  author   = {Haggai Maron, Heli Ben-Hamu, Hadar Serviansky, Yaron Lipman},
  title    = {Provably Powerful Graph Networks},
  year     = {2019},
  abstract = {Neural Information Processing Systems http://nips.cc/},
  eprint   = {1905.11136},
  file     = {:/home/fabrice/Documents/library/papers/2019_Maron_NIPS.pdf:PDF},
}

@Article{2019_Monti_Article,
  author  = {Monti, Federico and Frasca, Fabrizio and Eynard, Davide and Mannion, Damon and Bronstein, Michael M.},
  journal = {arXiv preprint arXiv:1902.06673},
  title   = {Fake news detection on social media using geometric deep learning},
  year    = {2019},
  eprint  = {1902.06673},
  file    = {:/home/fabrice/Documents/library/papers/2019_Monti_CONF.pdf:PDF},
}

@InProceedings{2019_Rieck_InProceedings,
  author   = {Bastian Rieck, Christian Bock, Karsten Borgwardt},
  title    = {A Persistent Weisfeiler–Lehman Procedure for Graph Classification},
  year     = {2019},
  abstract = {Proceedings of the International Conference on Machine Learning 2019},
  file     = {:/home/fabrice/Documents/library/papers/2019_Rieck_PMLR.pdf:PDF},
  keywords = {Weisfeiler-Lehman, Topological Data Analysis, Persistent Homology, Graph Classification, Cycles},
}

@InProceedings{2019_Schulz_InProceedings,
  author         = {Schulz, Till and Welke, Pascal},
  booktitle      = {ECML-PKDD, GEM workshop},
  title          = {{O}n the {N}ecessity of {G}raph {K}ernel {B}aselines},
  year           = {2019},
  number         = {2},
  pages          = {6},
  volume         = {1},
  file           = {:/home/fabrice/Documents/library/papers/2019_Schulz_CONF.pdf:PDF},
  qualityassured = {qualityAssured},
  url            = {https://gem-ecmlpkdd.github.io/archive/2019/papers/GEM2019_paper_17.pdf},
}

@InProceedings{2019_Togninalli_InProceedings,
  author   = {Matteo Togninalli, Elisabetta Ghisu, Felipe Llinares-López, Bastian Rieck, Karsten Borgwardt},
  title    = {Wasserstein Weisfeiler-Lehman Graph Kernels},
  year     = {2019},
  abstract = {Neural Information Processing Systems http://nips.cc/},
  eprint   = {1906.01277},
  file     = {:/home/fabrice/Documents/library/papers/2019_Togninalli_NIPS.pdf:PDF},
}

@InProceedings{2019_POWERFUL_InProceedingsa,
  author = {HOW POWERFUL and ARE GRAPH and NEURAL NETWORKS},
  title  = {Published as a conference paper at ICLR},
  year   = {2019},
  file   = {:/home/fabrice/Documents/library/papers/2019_Xu_CONF.pdf:PDF},
}

@Article{chami2020low,
  author         = {Chami, Ines and Wolf, Adva and Juan, Da-Cheng and Sala, Frederic and Ravi, Sujith and R{\'e}, Christopher},
  journal        = {arXiv preprint arXiv:2005.00545},
  title          = {Low-dimensional hyperbolic knowledge graph embeddings},
  year           = {2020},
  abstract       = {Knowledge graph (KG) embeddings learn low-
dimensional representations of entities and re-
lations to predict missing facts. KGs often ex-
hibit hierarchical and logical patterns which
must be preserved in the embedding space.
For hierarchical data, hyperbolic embedding
methods have shown promise for high-fidelity
and parsimonious representations. However,
existing hyperbolic embedding methods do
not account for the rich logical patterns in
KGs. In this work, we introduce a class
of hyperbolic KG embedding models that si-
multaneously capture hierarchical and logi-
cal patterns. Our approach combines hyper-
bolic reflections and rotations with attention
to model complex relational patterns. Exper-
imental results on standard KG benchmarks
show that our method improves over previ-
ous Euclidean- and hyperbolic-based efforts
by up to 6.1% in mean reciprocal rank (MRR)
in low dimensions. Furthermore, we observe
that different geometric transformations cap-
ture different types of relations while attention-
based transformations generalize to multiple
relations. In high dimensions, our approach
yields new state-of-the-art MRRs of 49.6% on
WN18RR and 57.7% on YAGO3-10.},
  doi            = {ng},
  file           = {:/home/fabrice/Documents/library/papers/2020_Chami_CONF.pdf:PDF},
  qualityassured = {qualityAssured},
}

@Article{cohen2020estimating,
  author         = {Cohen, Samuel and Arbel, Michael and Deisenroth, Marc Peter},
  journal        = {arXiv preprint arXiv:2007.07105},
  title          = {Estimating barycenters of measures in high dimensions},
  year           = {2020},
  abstract       = {Barycenters are principled summaries of popula-
tions of measures. To estimate barycenters, we
typically parametrize them as weighted sums of
Diracs and optimize their weights and/or loca-
tions. This approach, however, does not scale to
high dimensions due to the curse of dimensional-
ity. In this paper, we propose a technique for fa-
cilitating difficult barycenter estimation problems
through a different parametrization of the barycen-
ter by means of a generative model. This turns the
barycenter estimation into an optimization prob-
lem over model parameters, which sidesteps the
curse of dimensionality and allows for incorpo-
rating inductive biases directly into the model.
We prove local convergence under mild assump-
tions on the discrepancy, thereby showing that
the approach is well-posed. We demonstrate that
our method achieves good performance on low-
dimensional problems and provide unprecedented
results by scaling barycenter estimation effec-
tively to high-dimensional image data.},
  eprint         = {2007.07105},
  file           = {:/home/fabrice/Documents/library/papers/2020_Cohen_CONF.pdf:PDF},
  keywords       = {Machine Learning, ICML},
  qualityassured = {qualityAssured},
}

@Article{2020_Dwivedi_Article,
  author         = {Dwivedi, Vijay Prakash and Joshi, Chaitanya K. and Laurent, Thomas and Bengio, Yoshua and Bresson, Xavier},
  title          = {Benchmarking graph neural networks},
  year           = {2020},
  eprint         = {2003.00982},
  file           = {:/home/fabrice/Documents/library/papers/2020_Dwivedi_CONF.pdf:PDF},
  groups         = {AppliedGraphtheory, Graph Neural Networks},
  publisher      = {Mar},
  qualityassured = {qualityAssured},
}

@Book{2020_Hamilton_Book,
  author    = {William L. Hamilton},
  publisher = {Springer International Publishing},
  title     = {Graph Representation Learning},
  year      = {2020},
  doi       = {10.1007/978-3-031-01588-5},
  file      = {:/home/fabrice/Documents/library/papers/2020_Hamilton_BOOK.pdf:PDF},
}

@InProceedings{2020_Hu_InProceedings,
  author = {Weihua Hu and Matthias Fey and Marinka Zitnik and Yuxiao Dong and Hongyu Ren and Bowen Liu and Michele Catasta and Jure Leskovec},
  title  = {Open Graph Benchmark: Datasets for Machine Learning on Graphs},
  year   = {2020},
  eprint = {2005.00687},
  file   = {:/home/fabrice/Documents/library/papers/2020_Hu_CONF.pdf:PDF},
}

@Article{mirhoseini2020chip,
  author         = {Mirhoseini, Azalia and Goldie, Anna and Yazgan, Mustafa and Jiang, Joe and Songhori, Ebrahim and Wang, Shen and Lee, Young-Joon and Johnson, Eric and Pathak, Omkar and Bae, Sungmin and others},
  journal        = {arXiv preprint arXiv:2004.10746},
  title          = {Chip placement with deep reinforcement learning},
  year           = {2020},
  abstract       = {In this work, we present a learning-based ap-
proach to chip placement, one of the most com-
plex and time-consuming stages of the chip de-
sign process. Unlike prior methods, our approach
has the ability to learn from past experience and
improve over time. In particular, as we train
over a greater number of chip blocks, our method
becomes better at rapidly generating optimized
placements for previously unseen chip blocks.
To achieve these results, we pose placement as a
Reinforcement Learning (RL) problem and train
an agent to place the nodes of a chip netlist onto
a chip canvas. To enable our RL policy to gen-
eralize to unseen blocks, we ground representa-
tion learning in the supervised task of predicting
placement quality. By designing a neural archi-
tecture that can accurately predict reward across
a wide variety of netlists and their placements,
we are able to generate rich feature embeddings
of the input netlists. We then use this architec-
ture as the encoder of our policy and value net-
works to enable transfer learning. Our objec-
tive is to minimize PPA (power, performance,
and area), and we show that, in under 6 hours,
our method can generate placements that are su-
perhuman or comparable on modern accelerator
netlists, whereas existing baselines require hu-
man experts in the loop and take several weeks.},
  eprint         = {2004.10746},
  file           = {:/home/fabrice/Documents/library/papers/2020_Mirhoseini_CONF.pdf:PDF},
  qualityassured = {qualityAssured},
}

@InProceedings{2020_Morris_InProceedings,
  author   = {Christopher Morris, Nils M.Kriege, Franka Bause, Kristian Kersting, Petra Mutzel, Marion Neumann},
  title    = {TUDataset: A collection of benchmark datasets for learning with graphs},
  year     = {2020},
  abstract = {Graph Representation Learning and Beyond (GRL+), ICML 2020 Workshop},
  file     = {:/home/fabrice/Documents/library/papers/2020_Morris_CONF.pdf:PDF},
  keywords = {graph learning, graph kernel, weisfeiler, leman, gnn, graph neural network, benchmark datasets},
}

@InProceedings{2020_SanchezGonzalez_InProceedings,
  author   = {Alvaro Sanchez-Gonzalez, Jonathan Godwin, Tobias Pfaff, Rex Ying, Jure Leskovec, Peter W. Battaglia},
  title    = {Learning to Simulate Complex Physics with Graph Networks},
  year     = {2020},
  abstract = {Proceedings of the International Conference on Machine Learning 2020},
  eprint   = {2002.09405},
  file     = {:/home/fabrice/Documents/library/papers/2020_Sanchey-Gonzalez_PMLR.pdf:PDF},
  keywords = {Machine Learning, Graph Neural Networks, Physical Simulation, Particle-based Fluid Simulation},
}

@InProceedings{2020_GraKeL_InProceedings,
  author   = {GraKeL: A and Graph Kernel and Library in Python},
  title    = {Journal of Machine Learning Research 21 (2020) 1-5 Submitted 6/18; Revised 3/20; Published},
  year     = {2020},
  file     = {:/home/fabrice/Documents/library/papers/2020_Siglidis_JMLR.pdf:PDF},
  keywords = {graph similarity, graph kernels, scikit-learn, Python},
}

@InProceedings{2021_GRAPH_InProceedings,
  author = {REVISITING GRAPH and NEURAL NETWORKS and FOR LINK and PREDICTION},
  title  = {Under review as a conference paper at ICLR},
  year   = {2021},
  file   = {:/home/fabrice/Documents/library/papers/2020_Zhang_CONF.pdf:PDF},
}

@InProceedings{2021_Python_InProceedings,
  author   = {POT: Python and Optimal Transport},
  title    = {Journal of Machine Learning Research 22 (2021) 1-8 Submitted 5/20; Revised 1/21; Published},
  year     = {2021},
  abstract = {Optimal transport has recently been reintroduced to the machine learning community
thanks in part to novel efficient optimization procedures allowing for medium to large scale
applications. We propose a Python toolbox that implements several key optimal transport
ideas for the machine learning community. The toolbox contains implementations of a
number of founding works of OT for machine learning such as Sinkhorn algorithm and
Wasserstein barycenters, but also provides generic solvers that can be used for conducting
novel fundamental research. This toolbox, named POT for Python Optimal Transport, is
open source with an MIT license.
Keywords: Optimal transport, divergence, optimization, domain adaptation},
  file     = {:/home/fabrice/Documents/library/papers/2021_Flamary_JMLR.pdf:PDF},
}

@InProceedings{2110_Schulz_InProceedings,
  author   = {Till H. Schulz and Pascal Welke and Stefan Wrobel},
  title    = {Graph Filtration Kernels},
  year     = {2110},
  abstract = {substructures in terms of equivalence. We refer to these ker-
nels as histogram kernels. While they prove to be successful},
  eprint   = {2110.11862},
  file     = {:/home/fabrice/Documents/library/papers/2021_Schulz_CONFa.pdf:PDF},
}

@InProceedings{2022_ison_InProceedings,
  author   = {ison and because the two work processes—index operation and may be erroneously attributed to a weakness in the index and output scanning—can be worked on separately. The and but is actually a weakness or misuse of the display. and frequent confounding of these operations by the user In summary and the two steps of index using and display and is because the index-couples and which are at the heart of scanning are often confused and particularly in subordinate and index using and frequently carry the display also and as with indexes. It is submitted that distinguishing between and card catalogs or subject heading indexes such as Chemical and these two work processes results in better system design. and Abstracts. Thus and the user subconsciously proceeds from and using the index-couples to using the display and to which and the former have guided him. This and intertwining of the REFERENCES},
  title    = {The Generation of a Unique Machine Description for Chemical Structures-A Technique Developed at Chemical Abstracts Service.},
  year     = {2022},
  file     = {:/home/fabrice/Documents/library/papers/1965_Morgan_CONF.pdf:PDF},
  keywords = {article doi: 10.1021/c160017a018, Article metadata: Journal of Chemical Documentation_5_2_10.1021/c160017a018_107_113},
}

@Article{1990_Perona_Article,
  author         = {Perona, Pietro and Malik, Jitendra},
  journal        = {IEEE Transactions on pattern analysis and machine intelligence},
  title          = {Scale-space and edge detection using anisotropic diffusion},
  year           = {1990},
  number         = {7},
  pages          = {629--639},
  volume         = {12},
  file           = {:/home/fabrice/Documents/library/papers/1990_Perona_IEEE.pdf:PDF},
  publisher      = {IEEE},
  qualityassured = {qualityAssured},
  url            = {https://ieeexplore.ieee.org/abstract/document/56205/},
}

@Article{1991_Debnath_Article,
  author         = {Debnath, Asim Kumar and Lopez de Compadre, Rosa L. and Debnath, Gargi and Shusterman, Alan J. and Hansch, Corwin},
  journal        = {Journal of medicinal chemistry},
  title          = {Structure-activity relationship of mutagenic aromatic and heteroaromatic nitro compounds. correlation with molecular orbital energies and hydrophobicity},
  year           = {1991},
  number         = {2},
  pages          = {786--797},
  volume         = {34},
  file           = {:/home/fabrice/Documents/library/papers/1991_Debnath_CONF.pdf:PDF},
  keywords       = {article doi: 10.1021/jm00106a046, Article metadata: Journal of Medicinal Chemistry_34_2_10.1021/jm00106a046_786_797},
  publisher      = {ACS Publications},
  qualityassured = {qualityAssured},
  url            = {https://pubs.acs.org/doi/pdf/10.1021/jm00106a046?casa_token=hXhkXyPYg4cAAAAA:MHa5W2_ZQQuQSIcZuOrS7mSNxtTc4Yrl9Qb4CFMqBA1JJ5ikohx2xbw-qexg46Q9SSnb5sQ6R9lPOp3C},
}

@TechReport{1999_Haussler_TechReport,
  author         = {Haussler, David and others},
  institution    = {Citeseer},
  title          = {Convolution kernels on discrete structures},
  year           = {1999},
  file           = {:/home/fabrice/Documents/library/papers/1999_Haussler_CONF.pdf:PDF},
  qualityassured = {qualityAssured},
  url            = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=5ee0d8aeb2cb01ef4d8a858d234e72a7400c03ac},
}

@Article{2003_Belkin_Article,
  author         = {Belkin, Mikhail and Niyogi, Partha},
  journal        = {Neural computation},
  title          = {Laplacian eigenmaps for dimensionality reduction and data representation},
  year           = {2003},
  number         = {6},
  pages          = {1373--1396},
  volume         = {15},
  file           = {:/home/fabrice/Documents/library/papers/2003_Belkin_IEEE.pdf:PDF},
  publisher      = {MIT Press},
  qualityassured = {qualityAssured},
  url            = {https://ieeexplore.ieee.org/abstract/document/6789755/},
}

@Article{2003_Sutherland_Article,
  author         = {Sutherland, Jeffrey J. and O'brien, Lee A. and Weaver, Donald F.},
  journal        = {Journal of chemical information and computer sciences},
  title          = {Spline-fitting with a genetic algorithm: A method for developing classification structure- activity relationships},
  year           = {2003},
  number         = {6},
  pages          = {1906--1915},
  volume         = {43},
  file           = {:/home/fabrice/Documents/library/papers/2003_Sutherland_CONF.pdf:PDF},
  publisher      = {ACS Publications},
  qualityassured = {qualityAssured},
  url            = {https://pubs.acs.org/doi/abs/10.1021/ci034143r?casa_token=q4BygPbktY8AAAAA:793VOozUGISUJ98LYqDIHCEKF1xcMa2y0jLxkBkdHToasA84kiopxYkt8kwigQb8BAyoPlG4CkaoNvv9},
}

@InProceedings{9972_Efficient_InProceedings,
  author    = {An Efficient and Algorithm for and Discovering Frequent and Subgraphs},
  title     = {To appear in IEEE Transactions on Knowledge and Data Engineering},
  year      = {9972},
  publisher = {IEEE},
  abstract  = {Over the years, frequent itemset discovery algo- formulating the frequent pattern discovery problem is as that
rithms have been used to find interesting patterns in various of discovering subgraphs that occur frequently over the entire
application areas. However, as data mining techniques are being set of graphs.
increasingly applied to non-traditional domains, existing frequent
pattern discovery approach cannot be used. This is because The power of graphs to model complex datasets has been},
  file      = {:/home/fabrice/Documents/library/papers/2004_Kuramochi_IEEE.pdf:PDF},
}

@{2333_Nijssen_,
  abstract = {'  Q 	'I"=/
,-5"$
 %U0'/ ,'7/ '  v'	n  	 %b-, 
3 ,%5,   	   
  
 	
 			   	
  	! 	
#"$ ! 	%& '('
)" *	+'-, 
  	 ="C	< 3
 S[  ,   < P	%&  ' (' 
 $" 7D 0 I m:' L  '      FLu 
'm '&
.  # 
/  0'/
,' 
/ '  1 '  	+2 '	 2' 	 ' 0.34, &0   	  ' 2  /, 4 	 2 "$5 76 L\ !     0' &	 'P' 
L?&  % ('   I 'h b m !' P 	 ',= m  
 8" / 9" :'*<; / 
 ,3<
 "$ =" /
"9, 
>?7 ,&@ "$5
 =" /A"  ' -' 0 . '  ;
/   < ! 0'/,-' /
'   !< 3$ < '     	+' $
	 . ' *;</  P 	+'v'  # 	  
	 B C" 	D7=" / "E:'*;</  
,3<FHGID
	$" 
 % J  = /0 '/
,'/
'K 
6 	 K "$
1 '8 &
 
	%& '  ' 
 ",*	 % %*R{@|U}~?U NF
,%5/
L 	
   '   I	8 	' NF MO' 
  P/
0 '
/ , ' 
/ '  Q"C	 <3 uL 
"C	 5i-, 	% %  @K '
 
  %5 "$ < 1O ' 	 %& '( '
"
"$ 
 5
 R 	%&' '
"$S 	*C?  T 7 '&?*U WF VXW 7  S'4"C	Y  
+\'C %(n/K'
@
 , +3J7 '< ,  25 < 'C   - 	N% 
  	 
 	 
Z "$  
$ $" '@ $[  ,   < * ?\L8
 '?&8'] / 
'  R 0^ <; 
/ 5,<Y 6 $[ ,5 '(% <3 
F Vg
* 	 %5%(3<j ' = 	 % & '( '"   /5% 4 ?   *	 @ %5&Y S 	d?-6
0 	+4 
 ' , 5
 % _`D7%  '
 a'  Rb 	,J'+	 J 'c 	'  /J /7 6  , 5	% * C. '  ' $"  1\    $ m	  , * C\1(' ] :'   2 '   +	  		   
0 ' 
/ ,' /
'  d +	 ' J , &<	5 
 *e  ` *	-, e '  - *FfVga'
 J* 	',e .  7/ = 
 &/
:%  	%5Z ?i	% C ' c 7 * 	 P% 1\ (' T  	  = 	+	  	   S : 6

/ 
 6h0 '/ -, '
/ '   1>'0i +	 ' d	 'R, & 
 :7'*j 'k 	'
 i	+' >,5 ' %(3<F VX`' K 	 ?*2\Lc
* \ *q\ '
5 i,*	 B?c 7 &
 & 
 	0 .' "$*` 'l '   i	 e> 	%%3a'  i	'J	
0m' "$ k' 	T \PK* \'	+$ 'i	
% 5 , 	 '  &`n' K/,7Y 0 	+$
 '76
	 
  4F VgZ'  @ L\ 	 3l& 
C*, 	 W/
 ]"$ '$ [$ ,  <=	% &'(' $"  ,  %@,*	4 7  * K"C	 Y@	]7 ( j' ,8J ?  .'C" 	
 , &Fol@/
.# ' 
8  $" %@/ 
 0  '/ ,'7/ '  n	J& 
% K3 /8 ' 
= 	
	
, *4	 (% 6 @{ |U} ~?U $'n$"   P'
L x#¡PV¢ ££n	+	 	 !m   :' * ;</  <I 
/ 0 '/,-6
 '( '"$]1\   k ' 
  f3 	' 4 '* 	5% %(3f
  *
   UpF olR 5 "$
%   $"  < '*  ' /
'!	] 
/ , ,  0 ./% (% 3d, &"$ +	 ' 2'
 '$" $[ ,    
 ,C3  Q & /
!	 (% 6
	l
\q2  2r 
?s&t * ;</  
, + s uv'  J D	,-'. w zx Xy @{ U| }~?U v $	5%  6 &' ( '  "\1( '4	= /"=?- 1 I 0	 '-X6 .6 ' -6g+	 0 '/ ,'7/ '#$" 5

'('
"p	 *8 &S'I
 ' 
  ,  % 	@\L1
 '  '  
/ % ' &="$57 6 	 % '('$"  F ol
   *\¤' 	2 & /7n 	5%   ' (' "H,*	 R	5%  ]* 	5%(34? 
 
 $=	 5% 	' @$" %  , / 5% 	+ 
 		 	F /    $' 8
d  ¥2-'-  P$" 5
  #D7?  '"$ <' $ 1\  ,-CL\ 2, &"S6},
  author   = {Siegfried Nijssen and Joost N. Kok and LIACS and Leiden University LIACS and Leiden University},
  file     = {:/home/fabrice/Documents/library/papers/2004_Nijssen_CONF.pdf:PDF},
  keywords = {2r 8 -, Y  '/T Y *\1%*7 & d. C  / S ?  = \Li,&/%5 $"   6   J"$  7 I 0' / , ' 7/ '    "$(X6 0 ' / , ' / ' I     I.' ; /  < ' &W d%: +' &C/"8?#L/  %5 , '&  FiVXZ '# ? \LS\1 %% ('  " -' &  (% 3d'.  1 ' ='  , 1  /  %5 ,*+ '& F M},
  title    = {A Quickstart in Frequent Structure Mining can make a Difference},
  year     = {2333},
}

@Article{2004_Schomburg_Article,
  author         = {Schomburg, Ida and Chang, Antje and Ebeling, Christian and Gremse, Marion and Heldt, Christian and Huhn, Gregor and Schomburg, Dietmar},
  journal        = {Nucleic acids research},
  title          = {{BRENDA}, the enzyme database: updates and major new developments},
  year           = {2004},
  number         = {suppl\_1},
  pages          = {D431--D433},
  volume         = {32},
  abstract       = {progress of projects of structural and functional genomics and
metabolomics, the systematic collection, accessibility and},
  file           = {:/home/fabrice/Documents/library/papers/2004_Schomburg_CONF.pdf:PDF},
  publisher      = {Oxford University Press},
  qualityassured = {qualityAssured},
  url            = {https://academic.oup.com/nar/article-abstract/32/suppl_1/D431/2505276},
}

@InProceedings{2333_Gaston_InProceedings,
  author = {The Gaston and Tool for Frequent and Subgraph and Mining},
  title  = {GraBaTs’04 Preliminary Version},
  year   = {2333},
  file   = {:/home/fabrice/Documents/library/papers/2005_Nijssen_ENTCS.pdf:PDF},
}

@InProceedings{2009_Shervashidze_InProceedings,
  author         = {Shervashidze, Nino and Vishwanathan, S. V. N. and Petri, Tobias and Mehlhorn, Kurt and Borgwardt, Karsten},
  booktitle      = {Artificial intelligence and statistics},
  title          = {Efficient graphlet kernels for large graph comparison},
  year           = {2009},
  organization   = {PMLR},
  pages          = {488--495},
  abstract       = {Frequent subgraph mining algorithms, on the other
hand, aim to detect subgraphs that are frequent in
a given dataset of graphs. Afterwards, feature selec-},
  file           = {:/home/fabrice/Documents/library/papers/2009_Shervashidze_PMLR.pdf:PDF},
  groups         = {AppliedGraphtheory, Graph Kernels},
  qualityassured = {qualityAssured},
  url            = {https://proceedings.mlr.press/v5/shervashidze09a.html},
}

@InProceedings{4422_Fakultaet_InProceedings,
  author = {Fakultät and für Informatik and Algorithm Engineering and (LS 11) and 44221 Dortmund and / Germany and http://ls11-www.cs.uni-dortmund.de/},
  title  = {Erweiterte Substruktursuche in Moleküldatenbanken und ihre Integration in Scaffold Hunter Nils Kriege Algorithm Engineering Report TR10-1-001 Februar 2010 ISSN},
  year   = {4422},
  file   = {:/home/fabrice/Documents/library/papers/2010_Kriege_DISSERTATION.pdf:PDF},
}

@Article{2014_Chen_Article,
  author    = {Chen, Yudong and Sanghavi, Sujay and Xu, Huan},
  journal   = {IEEE Transactions on Information Theory},
  title     = {Improved graph clustering},
  year      = {2014},
  number    = {10},
  pages     = {6440--6455},
  volume    = {60},
  abstract  = {Graph clustering involves the task of dividing nodes • Small density gap: the edge density across clusters is
into clusters, so that the edge density is higher within clusters only a small additive or multiplicative factor different
as opposed to across clusters. A natural, classic and popular from within clusters;
statistical setting for evaluating solutions to this problem is the
stochastic block model, also referred to as the planted partition • Sparsity: the graph is overall very sparse even within
model. clusters;},
  file      = {:/home/fabrice/Documents/library/papers/2014_Chen_CONF.pdf:PDF},
  publisher = {IEEE},
  url       = {https://ieeexplore.ieee.org/abstract/document/6873307/},
}

@InProceedings{2015_FUNDAMENTALS_InProceedings,
  author = {FUNDAMENTALS OF and MACHINE LEARNING and FOR and PREDICTIVE DATA and ANALYTICS and Algorithms and Worked Examples and Case Studies},
  title  = {FreeChapter˙InformationBasedLearning 2015/6/12 18:02 Page i},
  year   = {2015},
  file   = {:/home/fabrice/Documents/library/papers/2015_Kelleher_BOOK.pdf:PDF},
}

@InProceedings{2017_CLASSIFICATION_InProceedings,
  author = {SEMI-SUPERVISED CLASSIFICATION and WITH and GRAPH CONVOLUTIONAL and NETWORKS},
  title  = {Published as a conference paper at ICLR},
  year   = {2017},
  file   = {:/home/fabrice/Documents/library/papers/2016_Kipf_ICLR.pdf:PDF},
}

@Book{2011_Korte_Book,
  author         = {Korte, Bernhard H. and Vygen, Jens and Korte, B. and Vygen, J.},
  publisher      = {Springer},
  title          = {Combinatorial optimization},
  year           = {2011},
  volume         = {1},
  file           = {:/home/fabrice/Documents/library/papers/2018_Korte_BOOK.pdf:PDF},
  groups         = {AppliedGraphtheory},
  qualityassured = {qualityAssured},
  url            = {https://link.springer.com/content/pdf/10.1007/978-3-662-56039-6.pdf},
}

@InCollection{2018_Schlichtkrull_InCollection,
  author    = {Michael Schlichtkrull and Thomas N. Kipf and Peter Bloem and Rianne van~den Berg and Ivan Titov and Max Welling},
  booktitle = {The Semantic Web},
  publisher = {Springer International Publishing},
  title     = {Modeling Relational Data with Graph Convolutional Networks},
  year      = {2018},
  pages     = {593--607},
  abstract  = {:country},
  doi       = {10.1007/978-3-319-93417-4_38},
  file      = {:/home/fabrice/Documents/library/papers/2018_Schlichtkrull_LNCS.pdf:PDF},
}

@Article{2019_Cranmer_Article,
  author  = {Cranmer, Miles D and Xu, Rui and Battaglia, Peter and Ho, Shirley},
  journal = {arXiv preprint arXiv:1909.05862},
  title   = {Learning symbolic physics with graph networks},
  year    = {2019},
  file    = {:/home/fabrice/Documents/library/papers/2019_Cranmer_NIPS.pdf:PDF},
  url     = {https://arxiv.org/abs/1909.05862},
}

@InProceedings{2019_Murphy_InProceedings,
  author   = {Ryan L. Murphy and 1 Balasubramaniam and Srinivasan and Vinayak Rao and 1 Bruno and Ribeiro},
  title    = {Relational Pooling for Graph Representations},
  year     = {2019},
  abstract = {ing problems, having a most-powerful framework for graph
This work generalizes graph neural networks representation learning would be a key development in ge-
(GNNs) beyond those based on the Weisfeiler- ometric deep learning (Bronstein et al., 2017).
Lehman (WL) algorithm, graph Laplacians, and
diffusions. Our approach, denoted Relational In this work we introduce Relational Pooling (RP), a novel},
  eprint   = {1903.02541},
  file     = {:/home/fabrice/Documents/library/papers/2019_Murphy_ICML.pdf:PDF},
}

@Book{2019_Peyre_Book,
  author    = {Gabriel Peyré and Marco Cuturi and and CNRSDMA and ENS Google and CREST and ENSAE},
  publisher = {now Publishers Inc},
  title     = {Computational Optimal Transport},
  year      = {2019},
  doi       = {10.1561/9781680835519},
  file      = {:/home/fabrice/Documents/library/papers/2019_Peyre.pdf:PDF},
}

@InProceedings{2020_ON_InProceedings,
  author   = {ON THE and EQUIVALENCE BETWEEN and POSITIONAL NODE and EMBEDDINGS AND and STRUCTURAL GRAPH and REPRESEN- and TATIONS},
  title    = {Published as a conference paper at ICLR},
  year     = {2020},
  abstract = {This work provides the first unifying theoretical framework for node (positional)
embeddings and structural graph representations, bridging methods like matrix
factorization and graph neural networks. Using invariant theory, we show that
the relationship between structural representations and node embeddings is anal-
ogous to that of a distribution and its samples. We prove that all tasks that can
be performed by node embeddings can also be performed by structural represen-
tations and vice-versa. We also show that the concept of transductive and induc-
tive learning is unrelated to node embeddings and graph representations, clearing
another source of confusion in the literature. Finally, we introduce new practi-
cal guidelines to generating and using node embeddings, which fixes significant
shortcomings of standard operating procedures used today.},
  file     = {:/home/fabrice/Documents/library/papers/2019_Srinivasan.pdf:PDF},
}

@InProceedings{2101_Hendrik_InProceedings,
  author   = {Till Hendrik and Schulz and Tamás Horváth and ∗† Pascal and Welke and Stefan Wrobel and ∗†},
  title    = {A Generalized Weisfeiler-Lehman Graph Kernel},
  year     = {2101},
  abstract = {more than it resembles T3, the Weisfeiler-Lehman ker-
The Weisfeiler-Lehman graph kernels are among the most nel [11] simply treats them all as unequal and is thus
prevalent graph kernels due to their remarkable time com- unable to quantify the apparent difference among the
plexity and predictive performance. Their key concept is
based on an implicit comparison of neighborhood repre- pairwise similarities between the unfolding trees.
senting trees with respect to equality (i.e., isomorphism). Motivated by these considerations, we relax the
This binary valued comparison is, however, arguably too above strictness by proposing a method which com-
rigid for defining suitable similarity measures over graphs.
To overcome this limitation, we propose a generalization of pares Weisfeiler-Lehman labels, or equivalently unfold-
Weisfeiler-Lehman graph kernels which takes into account ing trees, with regard to a much finer similarity measure
the similarity between trees rather than equality. We achieve than the binary valued one. More precisely, we employ
this using a specifically fitted variation of the well-known tree
edit distance which can efficiently be calculated. We em- a similarity between Weisfeiler-Lehman labels based on
pirically show that our approach significantly outperforms the concept of tree edit distances between their respec-
state-of-the-art methods in terms of predictive performance tive unfolding trees. These kind of distances provide
on datasets containing structurally more complex graphs be-
yond the typically considered molecular graphs. a natural comparison for trees. On an abstract level,},
  eprint   = {2101.08104},
  file     = {:/home/fabrice/Documents/library/papers/2021_Schulz_CONF.pdf:PDF},
}

@InProceedings{2008_Bach_InProceedings,
  author         = {Francis R. Bach},
  booktitle      = {Proceedings of the 25th international conference on Machine learning - {ICML} {\textquotesingle}08},
  title          = {{G}raph {K}ernels between {P}oint {C}louds},
  year           = {2008},
  publisher      = {{ACM} Press},
  abstract       = {point clouds, with applications to classification of line
drawings—such as handwritten digits (LeCun et al., 1998)},
  doi            = {10.1145/1390156.1390160},
  file           = {:/home/fabrice/Documents/library/papers/2008_Bach_ICML.pdf:PDF},
  groups         = {AppliedGraphtheory},
  qualityassured = {qualityAssured},
}

@Article{2013_Abubaker_Article,
  author         = {Abubaker, Mohamed and Ashour, Wesam},
  journal        = {Int. J. Intell. Syst. Appl},
  title          = {{E}fficient data clustering algorithms: improvements over {K}means},
  year           = {2013},
  number         = {3},
  pages          = {37--49},
  volume         = {5},
  abstract       = {This paper presents a new approach to The clustering problems can be categorized into two},
  file           = {:/home/fabrice/Documents/library/papers/2013_Abubaker_CONF.pdf:PDF},
  qualityassured = {qualityAssured},
  readstatus     = {read},
  url            = {https://www.mecs-press.org/ijisa/ijisa-v5-n3/IJISA-V5-N3-4.pdf},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: fileDirectory:/home/fabrice/Documents/library/papers;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:Analysis\;0\;1\;0x0000ffff\;MATH_INTEGRAL\;\;;
1 StaticGroup:AppliedGraphtheory\;0\;1\;0x008000ff\;GRAPH_OUTLINE\;\;;
2 StaticGroup:Graph Kernels\;0\;1\;0x008000ff\;\;\;;
1 StaticGroup:Machine Learning\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:Graph Neural Networks\;0\;0\;0x669966ff\;GRAPHQL\;\;;
2 StaticGroup:Convolutional networks\;0\;1\;0x664db3ff\;LAYERS_TRIPLE_OUTLINE\;\;;
2 StaticGroup:ReinforcementLearning\;0\;1\;0xffff00ff\;ROBOT_CONFUSED\;\;;
2 StaticGroup:Support Vector Machines\;0\;1\;0x8a8a8aff\;\;\;;
}

@Comment{jabref-meta: saveActions:disabled;
all-text-fields[identity]
date[normalize_date]
month[normalize_month]
pages[normalize_page_numbers]
;}
