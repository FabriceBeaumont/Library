@Article{1965_Morgan_Article,
  author         = {H. L. Morgan},
  journal        = {Journal of Chemical Documentation},
  title          = {The Generation of a Unique Machine Description for Chemical Structures-A Technique Developed at Chemical Abstracts Service.},
  year           = {1965},
  month          = {may},
  number         = {2},
  pages          = {107--113},
  volume         = {5},
  doi            = {10.1021/c160017a018},
  file           = {:1965_Morgan_CONF.pdf:PDF},
  keywords       = {article doi: 10.1021/c160017a018, Article metadata: Journal of Chemical Documentation_5_2_10.1021/c160017a018_107_113},
  publisher      = {American Chemical Society ({ACS})},
  qualityassured = {qualityAssured},
}

@InProceedings{1990_Perona_InProceedings,
  author         = {Perona, P. and Malik, J.},
  title          = {Scale-space and edge detection using anisotropic diffusion},
  year           = {1990},
  number         = {7},
  pages          = {629-639},
  publisher      = {IEEE},
  volume         = {12},
  doi            = {10.1109/34.56205},
  file           = {:1990_Perona_IEEE.pdf:PDF},
  journal        = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  qualityassured = {qualityAssured},
  url            = {https://ieeexplore.ieee.org/abstract/document/56205/},
}

@Article{1991_Debnath_Article,
  author         = {Asim Kumar Debnath and Rosa L. Lopez de Compadre and Gargi Debnath and Alan J. Shusterman and Corwin Hansch},
  journal        = {Journal of Medicinal Chemistry},
  title          = {Structure-activity relationship of mutagenic aromatic and heteroaromatic nitro compounds. Correlation with molecular orbital energies and hydrophobicity},
  year           = {1991},
  month          = {feb},
  number         = {2},
  pages          = {786--797},
  volume         = {34},
  doi            = {10.1021/jm00106a046},
  file           = {:1991_Debnath_CONF.pdf:PDF},
  keywords       = {article doi: 10.1021/jm00106a046, Article metadata: Journal of Medicinal Chemistry_34_2_10.1021/jm00106a046_786_797},
  publisher      = {American Chemical Society ({ACS})},
  qualityassured = {qualityAssured},
}

@InProceedings{2003_Barla_InProceedingsa,
  author         = {Barla, A. and Odone, F. and Verri, A.},
  booktitle      = {Proceedings 2003 International Conference on Image Processing (Cat. No.03CH37429)},
  title          = {Histogram intersection kernel for image classification},
  year           = {2003},
  pages          = {III-513},
  volume         = {3},
  doi            = {10.1109/ICIP.2003.1247294},
  file           = {:2003_Barla_CONF.pdf:PDF},
  qualityassured = {qualityAssured},
  url            = {https://ieeexplore.ieee.org/abstract/document/1247294/},
}

@InProceedings{2003_Belkin_InProceedings,
  author         = {Belkin, Mikhail and Niyogi, Partha},
  title          = {{L}aplacian {E}igenmaps for {D}imensionality {R}eduction and {D}ata {R}epresentation},
  year           = {2003},
  number         = {6},
  pages          = {1373-1396},
  volume         = {15},
  doi            = {10.1162/089976603321780317},
  file           = {:2003_Belkin_IEEE.pdf:PDF},
  journal        = {Neural Computation},
  qualityassured = {qualityAssured},
  url            = {https://ieeexplore.ieee.org/abstract/document/6789755/},
}

@InProceedings{2005_Deshpande_InProceedings,
  author         = {Deshpande, M. and Kuramochi, M. and Wale, N. and Karypis, G.},
  title          = {Frequent substructure-based approaches for classifying chemical compounds},
  year           = {2005},
  number         = {8},
  pages          = {1036-1050},
  volume         = {17},
  doi            = {10.1109/TKDE.2005.127},
  file           = {:2003_Deshpande_TECH_REPORT.pdf:PDF},
  groups         = {Graphtheory},
  journal        = {IEEE Transactions on Knowledge and Data Engineering},
  qualityassured = {qualityAssured},
  url            = {https://ieeexplore.ieee.org/abstract/document/1458698/},
}

@InProceedings{2003_Gaertner_InProceedingsa,
  author         = {G{\"a}rtner, Thomas and Flach, Peter and Wrobel, Stefan},
  booktitle      = {Learning Theory and Kernel Machines},
  title          = {{O}n {G}raph {K}ernels: {H}ardness {R}esults and {E}fficient {A}lternatives},
  year           = {2003},
  address        = {Berlin, Heidelberg},
  editor         = {Sch{\"o}lkopf, Bernhard and Warmuth, Manfred K.},
  pages          = {129--143},
  publisher      = {Springer Berlin Heidelberg},
  abstract       = {As most `real-world' data is structured, research in kernel methods has begun investigating kernels for various kinds of structured data. One of the most widely used tools for modeling structured data are graphs. An interesting and important challenge is thus to investigate kernels on instances that are represented by graphs. So far, only very specific graphs such as trees and strings have been considered.},
  doi            = {10.1007/978-3-540-45167-9_11},
  file           = {:2003_Gaertner_CONF.pdf:PDF},
  groups         = {GraphKernels},
  isbn           = {978-3-540-45167-9},
  qualityassured = {qualityAssured},
}

@Article{2003_Sutherland_Article,
  author         = {Jeffrey J. Sutherland and Lee A. O{\textquotesingle}Brien and Donald F. Weaver},
  journal        = {Journal of Chemical Information and Computer Sciences},
  title          = {{S}pline-{F}itting with a {G}enetic {A}lgorithm: {A} {M}ethod for {D}eveloping {C}lassification {S}tructure-{A}ctivity {R}elationships},
  year           = {2003},
  month          = {oct},
  number         = {6},
  pages          = {1906--1915},
  volume         = {43},
  doi            = {10.1021/ci034143r},
  file           = {:2003_Sutherland_CONF.pdf:PDF},
  publisher      = {American Chemical Society ({ACS})},
  qualityassured = {qualityAssured},
}

@InProceedings{2004_Kuramochi_InProceedings,
  author         = {Kuramochi, M. and Karypis, G.},
  title          = {An efficient algorithm for discovering frequent subgraphs},
  year           = {2004},
  number         = {9},
  pages          = {1038-1051},
  volume         = {16},
  abstract       = {Over the years, frequent itemset discovery algo- formulating the frequent pattern discovery problem is as that
rithms have been used to find interesting patterns in various of discovering subgraphs that occur frequently over the entire
application areas. However, as data mining techniques are being set of graphs.
increasingly applied to non-traditional domains, existing frequent
pattern discovery approach cannot be used. This is because The power of graphs to model complex datasets has been},
  doi            = {10.1109/TKDE.2004.33},
  file           = {:2004_Kuramochi_IEEE.pdf:PDF},
  groups         = {Graphtheory},
  journal        = {IEEE Transactions on Knowledge and Data Engineering},
  qualityassured = {qualityAssured},
  url            = {https://ieeexplore.ieee.org/abstract/document/1316833/},
}

@InProceedings{2004_Nijssen_InProceedings,
  author         = {Nijssen, Siegfried and Kok, Joost N.},
  booktitle      = {Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  title          = {{A} {Q}uickstart in {F}requent {S}tructure {M}ining {C}an {M}ake a {D}ifference},
  year           = {2004},
  address        = {New York, NY, USA},
  pages          = {647–652},
  publisher      = {Association for Computing Machinery},
  series         = {KDD '04},
  abstract       = {Given a database, structure mining algorithms search for substructures that satisfy constraints such as minimum frequency, minimum confidence, minimum interest and maximum frequency. Examples of substructures include graphs, trees and paths. For these substructures many mining algorithms have been proposed. In order to make graph mining more efficient, we investigate the use of the "quickstart principle", which is based on the fact that these classes of structures are contained in each other, thus allowing for the development of structure mining algorithms that split the search into steps of increasing complexity. We introduce the GrAph/Sequence/Tree extractiON (Gaston) algorithm that implements this idea by searching first for frequent paths, then frequent free trees and finally cyclic graphs. We investigate two alternatives for computing the frequency of structures and present experimental results to relate these alternatives.},
  doi            = {10.1145/1014052.1014134},
  file           = {:2004_Nijssen_CONF.pdf:PDF},
  groups         = {Graphtheory},
  isbn           = {1581138881},
  keywords       = {semi-structures, frequent item sets, structures, graphs},
  location       = {Seattle, WA, USA},
  numpages       = {6},
  qualityassured = {qualityAssured},
}

@Article{2004_Schomburg_Article,
  author         = {Schomburg, Ida and Chang, Antje and Ebeling, Christian and Gremse, Marion and Heldt, Christian and Huhn, Gregor and Schomburg, Dietmar},
  journal        = {Nucleic Acids Research},
  title          = {{BRENDA, the enzyme database: updates and major new developments}},
  year           = {2004},
  issn           = {0305-1048},
  month          = {01},
  number         = {suppl_1},
  pages          = {D431-D433},
  volume         = {32},
  abstract       = {{ BRENDA (BRaunschweig ENzyme DAtabase) represents a comprehensive collection of enzyme and metabolic information, based on primary literature. The database contains data from at least 83 000 different enzymes from 9800 different organisms, classified in ∼4200 EC numbers. BRENDA includes biochemical and molecular information on classification and nomenclature, reaction and specificity, functional parameters, occurrence, enzyme structure, application, engineering, stability, disease, isolation and preparation, links and literature references. The data are extracted and evaluated from ∼46 000 references, which are linked to PubMed as long as the reference is cited in PubMed. In the past year BRENDA has undergone major changes including a large increase in updating speed with \\&gt;50\\% of all data updated in 2002 or in the first half of 2003, the development of a new EC‐tree browser, a taxonomy‐tree browser, a chemical substructure search engine for ligand structure, the development of controlled vocabulary, an ontology for some information fields and a thesaurus for ligand names. The database is accessible free of charge to the academic community at http://www.brenda. uni‐koeln.de . }},
  doi            = {10.1093/nar/gkh081},
  eprint         = {https://academic.oup.com/nar/article-pdf/32/suppl\_1/D431/7621720/gkh081.pdf},
  file           = {:2004_Schomburg_CONF.pdf:PDF},
  qualityassured = {qualityAssured},
}

@Article{2005_Nijssen_Article,
  author         = {Siegfried Nijssen and Joost N. Kok},
  journal        = {Electronic Notes in Theoretical Computer Science},
  title          = {{T}he {G}aston {T}ool for {F}requent {S}ubgraph {M}ining},
  year           = {2005},
  issn           = {1571-0661},
  note           = {Proceedings of the International Workshop on Graph-Based Tools (GraBaTs 2004)},
  number         = {1},
  pages          = {77-87},
  volume         = {127},
  abstract       = {Given a database of graphs, structure mining algorithms search for all substructures that satisfy constraints such as minimum frequency, minimum confidence, minimum interest and maximum frequency. In order to make frequent subgraph mining more efficient, we propose to search with steps of increasing complexity. We present the GrAph/Sequence/Tree extractiON (Gaston) tool that implements this idea by searching first for frequent paths, then frequent free trees and finally cyclic graphs. We give results on large molecular databases.},
  doi            = {10.1016/j.entcs.2004.12.039},
  file           = {:2005_Nijssen_ENTCS.pdf:PDF},
  groups         = {Graphtheory},
  keywords       = {Frequent Subgraphs, Data Mining},
  qualityassured = {qualityAssured},
  url            = {https://www.sciencedirect.com/science/article/pii/S1571066105001064},
}

@InProceedings{2008_Bach_InProceedings,
  author         = {Bach, Francis R.},
  booktitle      = {Proceedings of the 25th International Conference on Machine Learning},
  title          = {{G}raph {K}ernels between {P}oint {C}louds},
  year           = {2008},
  address        = {New York, NY, USA},
  pages          = {25–32},
  publisher      = {Association for Computing Machinery},
  series         = {ICML '08},
  abstract       = {Point clouds are sets of points in two or three dimensions. Most kernel methods for learning on sets of points have not yet dealt with the specific geometrical invariances and practical constraints associated with point clouds in computer vision and graphics. In this paper, we present extensions of graph kernels for point clouds, which allow one to use kernel methods for such objects as shapes, line drawings, or any three-dimensional point clouds. In order to design rich and numerically efficient kernels with as few free parameters as possible, we use kernels between covariance matrices and their factorizations on probabilistic graphical models. We derive polynomial time dynamic programming recursions and present applications to recognition of handwritten digits and Chinese characters from few training examples.},
  doi            = {10.1145/1390156.1390160},
  file           = {:2008_Bach_ICML.pdf:PDF},
  groups         = {GraphKernels},
  isbn           = {9781605582054},
  location       = {Helsinki, Finland},
  numpages       = {8},
  qualityassured = {qualityAssured},
}

@InProceedings{2003_Shervashidze_InProceedings,
  author         = {Nino Shervashidze and S. V. N. Vishwanathan and Tobias H. Petri},
  title          = {Efficient graphlet kernels for large graph comparison},
  year           = {2003},
  abstract       = {Frequent subgraph mining algorithms, on the other
hand, aim to detect subgraphs that are frequent in
a given dataset of graphs. Afterwards, feature selec-},
  file           = {:2009_Shervashidze_PMLR.pdf:PDF},
  groups         = {GraphKernels},
  qualityassured = {qualityAssured},
  url            = {https://proceedings.mlr.press/v5/shervashidze09a.html},
}

@InProceedings{2009_Vert_InProceedingsa,
  author         = {Vert, Jean-Philippe and Matsui, Tomoko and Satoh, Shin'ichi and Uchiyama, Yuji},
  booktitle      = {2009 IEEE International Conference on Acoustics, Speech and Signal Processing},
  title          = {{H}igh-level feature extraction using {SVM} with walk-based graph kernel},
  year           = {2009},
  month          = {April},
  pages          = {1121-1124},
  abstract       = {We investigate a method using support vector machines (SVMs) with walk-based graph kernels for high-level feature extraction from images. In this method, each image is first segmented into a finite set of homogeneous segments and then represented as a segmentation graph where each vertex is a segment and edges connect adjacent segments. Given a set of features associated with each segment, we then obtain a positive definite kernel between images by comparing walks in the respective segmentation graphs, and image classification is carried out with an SVM based on this kernel. In a benchmark experiment on the MediaMill challenge problem, the mean average precision increased from 0.216 (baseline) to 0.341 when our method was utilized.},
  doi            = {10.1109/ICASSP.2009.4959785},
  file           = {:2009_Vert_IEEE.pdf:PDF},
  groups         = {SupportVectorMachines},
  issn           = {2379-190X},
  qualityassured = {qualityAssured},
  url            = {https://ieeexplore.ieee.org/abstract/document/4959785/},
}

@MastersThesis{2009_Kriege_MastersThesis,
  author         = {Nils M. Kriege},
  school         = {TU Dortmund},
  title          = {{E}rweiterte {S}ubstruktursuche in {M}olek{\"u}ldatenbanken und ihre {I}ntegration in {S}caffold {H}unter},
  year           = {2009},
  file           = {:2010_Kriege_DISSERTATION.pdf:PDF},
  qualityassured = {qualityAssured},
  url            = {http://eprints.cs.univie.ac.at/6761/},
}

@Article{2013_Abubaker_Article,
  author         = {Mohamed Abubaker and Wesam Ashour},
  journal        = {International Journal of Intelligent Systems and Applications},
  title          = {{E}fficient {D}ata {C}lustering {A}lgorithms: {I}mprovements over {K}means},
  year           = {2013},
  month          = {feb},
  number         = {3},
  pages          = {37--49},
  volume         = {5},
  abstract       = {This paper presents a new approach to The clustering problems can be categorized into two},
  doi            = {10.5815/ijisa.2013.03.04},
  file           = {:2013_Abubaker_CONF.pdf:PDF},
  groups         = {ClusteringAlgorithms},
  publisher      = {{MECS} Publisher},
  qualityassured = {qualityAssured},
  readstatus     = {read},
  url            = {https://www.mecs-press.org/ijisa/ijisa-v5-n3/IJISA-V5-N3-4.pdf},
}

@Article{2014_Chen_InProceedings,
  author         = {Chen, Yudong and Sanghavi, Sujay and Xu, Huan},
  journal        = {{IEEE} Transactions on Information Theory},
  title          = {{I}mproved {G}raph {C}lustering},
  year           = {2014},
  month          = {oct},
  number         = {10},
  pages          = {6440--6455},
  volume         = {60},
  abstract       = {Graph clustering involves the task of dividing nodes • Small density gap: the edge density across clusters is
into clusters, so that the edge density is higher within clusters only a small additive or multiplicative factor different
as opposed to across clusters. A natural, classic and popular from within clusters;
statistical setting for evaluating solutions to this problem is the
stochastic block model, also referred to as the planted partition • Sparsity: the graph is overall very sparse even within
model. clusters;},
  doi            = {10.1109/tit.2014.2346205},
  file           = {:2014_Chen_CONF.pdf:PDF},
  groups         = {GraphKernels},
  publisher      = {Institute of Electrical and Electronics Engineers ({IEEE})},
  qualityassured = {qualityAssured},
  url            = {https://ieeexplore.ieee.org/abstract/document/6873307},
}

@Book{2015_Kelleher_Book,
  author         = {John D. Kelleher and Brian Mac Namee and Aoife D'Arcy},
  title          = {Fundamentals of Machine Learning for Predictive Data Analytics},
  year           = {2015},
  file           = {:2015_Kelleher_BOOK.pdf:PDF},
  qualityassured = {qualityAssured},
  url            = {https://www.mencap.org.uk/sites/default/files/2021-03/pdf-fundamentals-of-machine-learning-for-predictive-data-analytics-a-john-d-kelleher-brian-mac-namee-aoife-darcy-pdf-download-free-book-d21caf4.pdf},
}

@InProceedings{2017_Kipf_InProceedings,
  author         = {Thomas N. Kipf and Max Welling},
  title          = {{S}emi-{S}upervised {C}lassification with {G}raph {C}onvolutional {N}etworks},
  year           = {2017},
  abstract       = {We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.},
  archiveprefix  = {arXiv},
  eprint         = {1609.02907},
  file           = {:2016_Kipf_ICLR.pdf:PDF},
  primaryclass   = {cs.LG},
  qualityassured = {qualityAssured},
}

@InProceedings{2017_Monti_InProceedings,
  author         = {Monti, Federico and Bronstein, Michael and Bresson, Xavier},
  booktitle      = {Advances in Neural Information Processing Systems},
  title          = {{G}eometric {M}atrix {C}ompletion with {R}ecurrent {M}ulti-{G}raph {N}eural {N}etworks},
  year           = {2017},
  editor         = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
  publisher      = {Curran Associates, Inc.},
  volume         = {30},
  abstract       = {Neural Information Processing Systems http://nips.cc/},
  file           = {:2017_Monti_CONF.pdf:PDF},
  qualityassured = {qualityAssured},
  url            = {https://proceedings.neurips.cc/paper_files/paper/2017/file/2eace51d8f796d04991c831a07059758-Paper.pdf},
}

@InProceedings{2018_Velickovic_InProceedings,
  author         = {Petar Veličković and Guillem Cucurull and Arantxa Casanova and Adriana Romero and Pietro Liò and Yoshua Bengio},
  title          = {{G}raph {A}ttention {N}etworks},
  year           = {2018},
  archiveprefix  = {arXiv},
  eprint         = {1710.10903},
  eprinttype     = {arxiv},
  file           = {:2017_Velickovic_ICLR.pdf:PDF},
  groups         = {GraphKernels},
  primaryclass   = {stat.ML},
  qualityassured = {qualityAssured},
}

@Article{2017_Welke_Article,
  author         = {Pascal Welke and Tam{\'{a}}s Horv{\'{a}}th and Stefan Wrobel},
  journal        = {Machine Learning},
  title          = {Probabilistic frequent subtrees for efficient graph classification and retrieval},
  year           = {2017},
  month          = {nov},
  number         = {11},
  pages          = {1847--1873},
  volume         = {107},
  abstract       = {Machine Learning, doi:10.1007/s10994-017-5688-7},
  doi            = {10.1007/s10994-017-5688-7},
  file           = {:2017_Welke_CONF.pdf:PDF},
  groups         = {Graphtheory},
  keywords       = {Pattern mining,Frequent subgraph mining,Frequent subtree mining,Probabilistic subtrees,Efficient embedding computation,Min-hashing},
  publisher      = {Springer Science and Business Media {LLC}},
  qualityassured = {qualityAssured},
}

@Article{2018_Gera_Article,
  author         = {Ralucca Gera and L. Alonso and Brian Crawford and Jeffrey House and J. A. Mendez-Bermudez and Thomas Knuth and Ryan Miller},
  journal        = {Applied Network Science},
  title          = {Identifying network structure similarity using spectral graph theory},
  year           = {2018},
  month          = {jan},
  number         = {1},
  volume         = {3},
  abstract       = {Appl Netw Sci, doi:10.1007/s41109-017-0042-3},
  doi            = {10.1007/s41109-017-0042-3},
  file           = {:2018_Gera_Springer.pdf:PDF},
  keywords       = {Network topology, Graph comparison metrics, Laplacian, Eigenvalue distribution, Kolmogorov-Smirnov test},
  publisher      = {Springer Science and Business Media {LLC}},
  qualityassured = {qualityAssured},
}

@Article{2019_Morris_Article,
  author         = {Christopher Morris and Martin Ritzert and Matthias Fey and William L. Hamilton and Jan Eric Lenssen and Gaurav Rattan and Martin Grohe},
  journal        = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
  title          = {Weisfeiler and Leman Go Neural: Higher-Order Graph Neural Networks},
  year           = {2019},
  month          = {jul},
  number         = {01},
  pages          = {4602--4609},
  volume         = {33},
  abstract       = {In recent years, graph neural networks (GNNs) have emerged as a powerful neural architecture to learn vector representations of nodes and graphs in a supervised, end-to-end fashion. Up to now, GNNs have only been evaluated empirically—showing promising results. The following work investigates GNNs from a theoretical point of view and relates them to the 1-dimensional Weisfeiler-Leman graph isomorphism heuristic (1-WL). We show that GNNs have the same expressiveness as the 1-WL in terms of distinguishing non-isomorphic (sub-)graphs. Hence, both algorithms also have the same shortcomings. Based on this, we propose a generalization of GNNs, so-called k-dimensional GNNs (k-GNNs), which can take higher-order graph structures at multiple scales into account. These higher-order structures play an essential role in the characterization of social networks and molecule graphs. Our experimental evaluation confirms our theoretical findings as well as confirms that higher-order information is useful in the task of graph classification and regression.},
  doi            = {10.1609/aaai.v33i01.33014602},
  file           = {:2018_Morris_AAAI.pdf:PDF},
  groups         = {GraphKernels},
  publisher      = {Association for the Advancement of Artificial Intelligence ({AAAI})},
  qualityassured = {qualityAssured},
  url            = {https://ojs.aaai.org/index.php/AAAI/article/view/4384},
}

@InCollection{2018_Schlichtkrull_InCollection,
  author         = {Michael Schlichtkrull and Thomas N. Kipf and Peter Bloem and Rianne van~den Berg and Ivan Titov and Max Welling},
  booktitle      = {The Semantic Web},
  publisher      = {Springer International Publishing},
  title          = {Modeling Relational Data with Graph Convolutional Networks},
  year           = {2018},
  pages          = {593--607},
  abstract       = {:country},
  doi            = {10.1007/978-3-319-93417-4_38},
  file           = {:2018_Schlichtkrull_LNCS.pdf:PDF},
  qualityassured = {qualityAssured},
}

@Misc{2008_Vert_Misc,
  author         = {Jean-Philippe Vert},
  title          = {The optimal assignment kernel is not positive definite},
  year           = {2008},
  archiveprefix  = {arXiv},
  eprint         = {0801.4061},
  eprinttype     = {arxiv},
  file           = {:2018_Vert_CONF.pdf:PDF},
  groups         = {GraphKernels},
  primaryclass   = {cs.LG},
  qualityassured = {qualityAssured},
  readstatus     = {skimmed},
}

@InProceedings{2019_Xu_InProceedings,
  author         = {Keyulu Xu and Weihua Hu and Jure Leskovec and Stefanie Jegelka},
  title          = {{H}ow {P}owerful are {G}raph {N}eural {N}etworks?},
  year           = {2019},
  archiveprefix  = {arXiv},
  eprint         = {1810.00826},
  eprinttype     = {arxiv},
  file           = {:2018_Xu_CONF.pdf:PDF},
  groups         = {GraphKernels},
  primaryclass   = {cs.LG},
  qualityassured = {qualityAssured},
}

@InProceedings{2018_Ying_InProceedings,
  author         = {Ying, Rex and He, Ruining and Chen, Kaifeng and Eksombatchai, Pong and Hamilton, William L. and Leskovec, Jure},
  booktitle      = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
  title          = {{G}raph {C}onvolutional {N}eural {N}etworks for {W}eb-{S}cale {R}ecommender {S}ystems},
  year           = {2018},
  address        = {New York, NY, USA},
  pages          = {974–983},
  publisher      = {Association for Computing Machinery},
  series         = {KDD '18},
  abstract       = {Recent advancements in deep neural networks for graph-structured data have led to state-of-the-art performance on recommender system benchmarks. However, making these methods practical and scalable to web-scale recommendation tasks with billions of items and hundreds of millions of users remains an unsolved challenge. Here we describe a large-scale deep recommendation engine that we developed and deployed at Pinterest. We develop a data-efficient Graph Convolutional Network (GCN) algorithm, which combines efficient random walks and graph convolutions to generate embeddings of nodes (i.e., items) that incorporate both graph structure as well as node feature information. Compared to prior GCN approaches, we develop a novel method based on highly efficient random walks to structure the convolutions and design a novel training strategy that relies on harder-and-harder training examples to improve robustness and convergence of the model. We also develop an efficient MapReduce model inference algorithm to generate embeddings using a trained model. Overall, we can train on and embed graphs that are four orders of magnitude larger than typical GCN implementations. We show how GCN embeddings can be used to make high-quality recommendations in various settings at Pinterest, which has a massive underlying graph with 3 billion nodes representing pins and boards, and 17 billion edges. According to offline metrics, user studies, as well as A/B tests, our approach generates higher-quality recommendations than comparable deep learning based systems. To our knowledge, this is by far the largest application of deep graph embeddings to date and paves the way for a new generation of web-scale recommender systems based on graph convolutional architectures.},
  doi            = {10.1145/3219819.3219890},
  file           = {:2018_Ying_KDD.pdf:PDF},
  groups         = {GraphKernels},
  isbn           = {9781450355520},
  keywords       = {graph convolutional networks, scalability, recommender systems, deep learning},
  location       = {London, United Kingdom},
  numpages       = {10},
  qualityassured = {qualityAssured},
}

@InProceedings{2019_Chen_InProceedings,
  author         = {Chen, Zhengdao and Villar, Soledad and Chen, Lei and Bruna, Joan},
  booktitle      = {Advances in Neural Information Processing Systems},
  title          = {{O}n the equivalence between graph isomorphism testing and function approximation with {GNN}s},
  year           = {2019},
  editor         = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  publisher      = {Curran Associates, Inc.},
  volume         = {32},
  abstract       = {Neural Information Processing Systems http://nips.cc/},
  file           = {:2019_Chen_NIPS.pdf:PDF},
  qualityassured = {qualityAssured},
  url            = {https://proceedings.neurips.cc/paper_files/paper/2019/file/71ee911dd06428a96c143a0b135041a4-Paper.pdf},
}

@InProceedings{2019_Cranmer_InProceedings,
  author         = {Miles D. Cranmer and Rui Xu and Peter Battaglia and Shirley Ho},
  title          = {{L}earning {S}ymbolic {P}hysics with {G}raph {N}etworks},
  year           = {2019},
  archiveprefix  = {arXiv},
  eprint         = {1909.05862},
  file           = {:2019_Cranmer_NIPS.pdf:PDF},
  primaryclass   = {cs.LG},
  qualityassured = {qualityAssured},
}

@InProceedings{2019_Ivanov_InProceedings,
  author         = {Sergei Ivanov and Sergei Sviridov and Evgeny Burnaev},
  title          = {{U}nderstanding {I}somorphism {B}ias in {G}raph {D}ata {S}ets},
  year           = {2019},
  archiveprefix  = {arXiv},
  eprint         = {1910.12091},
  file           = {:2019_Ivanov_CONF.pdf:PDF},
  primaryclass   = {cs.LG},
  qualityassured = {qualityAssured},
}

@InProceedings{2019_Lahn_InProceedings,
  author         = {Lahn, Nathaniel and Mulchandani, Deepika and Raghvendra, Sharath},
  booktitle      = {Advances in Neural Information Processing Systems},
  title          = {{A} {G}raph {T}heoretic {A}dditive {A}pproximation of {O}ptimal {T}ransport},
  year           = {2019},
  editor         = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  publisher      = {Curran Associates, Inc.},
  volume         = {32},
  abstract       = {Neural Information Processing Systems http://nips.cc/},
  file           = {:2019_Lahn_CONF.pdf:PDF},
  qualityassured = {qualityAssured},
  url            = {https://proceedings.neurips.cc/paper_files/paper/2019/file/9b07f50145902e945a1cc629f729c213-Paper.pdf},
}

@InProceedings{2019_Le_InProceedings,
  author         = {Le, Tam and Yamada, Makoto and Fukumizu, Kenji and Cuturi, Marco},
  booktitle      = {Advances in Neural Information Processing Systems},
  title          = {{T}ree-{S}liced {V}ariants of {W}asserstein {D}istances},
  year           = {2019},
  editor         = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  publisher      = {Curran Associates, Inc.},
  volume         = {32},
  file           = {:2019_Le_NIPS.pdf:PDF},
  groups         = {Graphtheory},
  qualityassured = {qualityAssured},
  url            = {https://proceedings.neurips.cc/paper_files/paper/2019/file/2d36b5821f8affc6868b59dfc9af6c9f-Paper.pdf},
}

@InProceedings{2019_PetricMaretic_InProceedings,
  author         = {Petric Maretic, Hermina and El Gheche, Mireille and Chierchia, Giovanni and Frossard, Pascal},
  booktitle      = {Advances in Neural Information Processing Systems},
  title          = {{GOT}: {A}n {O}ptimal {T}ransport framework for {G}raph comparison},
  year           = {2019},
  editor         = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  publisher      = {Curran Associates, Inc.},
  volume         = {32},
  file           = {:2019_Maretic_CONF.pdf:PDF},
  qualityassured = {qualityAssured},
  url            = {https://proceedings.neurips.cc/paper_files/paper/2019/file/fdd5b16fc8134339089ef25b3cf0e588-Paper.pdf},
}

@InProceedings{2019_Maron_InProceedings,
  author         = {Maron, Haggai and Ben-Hamu, Heli and Serviansky, Hadar and Lipman, Yaron},
  booktitle      = {Advances in Neural Information Processing Systems},
  title          = {{P}rovably {P}owerful {G}raph {N}etworks},
  year           = {2019},
  editor         = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  publisher      = {Curran Associates, Inc.},
  volume         = {32},
  abstract       = {Neural Information Processing Systems http://nips.cc/},
  file           = {:2019_Maron_NIPS.pdf:PDF},
  qualityassured = {qualityAssured},
  url            = {https://proceedings.neurips.cc/paper_files/paper/2019/file/bb04af0f7ecaee4aae62035497da1387-Paper.pdf},
}

@InProceedings{2019_Monti_InProceedings,
  author         = {Federico Monti and Fabrizio Frasca and Davide Eynard and Damon Mannion and Michael M. Bronstein},
  title          = {{F}ake {N}ews {D}etection on {S}ocial {M}edia using {G}eometric {D}eep {L}earning},
  year           = {2019},
  archiveprefix  = {arXiv},
  eprint         = {1902.06673},
  file           = {:2019_Monti_CONF.pdf:PDF},
  primaryclass   = {cs.SI},
  qualityassured = {qualityAssured},
}

@InProceedings{2019_Murphy_InProceedings,
  author         = {Murphy, Ryan and Srinivasan, Balasubramaniam and Rao, Vinayak and Ribeiro, Bruno},
  booktitle      = {Proceedings of the 36th International Conference on Machine Learning},
  title          = {{R}elational {P}ooling for {G}raph {R}epresentations},
  year           = {2019},
  editor         = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  month          = {09--15 Jun},
  pages          = {4663--4673},
  publisher      = {PMLR},
  series         = {Proceedings of Machine Learning Research},
  volume         = {97},
  abstract       = {This work generalizes graph neural networks (GNNs) beyond those based on the Weisfeiler-Lehman (WL) algorithm, graph Laplacians, and diffusions. Our approach, denoted Relational Pooling (RP), draws from the theory of finite partial exchangeability to provide a framework with maximal representation power for graphs. RP can work with existing graph representation models and, somewhat counterintuitively, can make them even more powerful than the original WL isomorphism test. Additionally, RP allows architectures like Recurrent Neural Networks and Convolutional Neural Networks to be used in a theoretically sound approach for graph classification. We demonstrate improved performance of RP-based graph representations over state-of-the-art methods on a number of tasks.},
  file           = {:2019_Murphy_ICML.pdf:PDF;murphy19a.pdf:http\:/proceedings.mlr.press/v97/murphy19a/murphy19a.pdf:PDF},
  qualityassured = {qualityAssured},
  url            = {https://proceedings.mlr.press/v97/murphy19a.html},
}

@TechReport{RePEc:crs:wpaper:2017-86,
  author         = {Gabriel Peyré and Marco Cuturi},
  institution    = {Center for Research in Economics and Statistics},
  title          = {{Computational Optimal Transport}},
  year           = {2017},
  month          = Oct,
  number         = {2017-86},
  type           = {Working Papers},
  abstract       = {Optimal Transport (OT) is a mathematical gem at the interface between probability, analysis and optimization. The goal of that theory is to define geometric tools that are useful to compare probability distributions. Let us briefly sketch some key ideas using a vocabulary that was first introduced by Monge two centuries ago: a probability distribution can be thought of as a pile of sand. Peaks indicate where likely observations are to appear. Given a pair of probability distributions—two different piles of sand—there are, in general, multiple ways to morph, transport or reshape the first pile so that it matches the second. To every such transport we associate an a “global” cost, using the “local” consideration of how much it costs to move a single grain of sand from one location to another. The goal of optimal transport is to find the least costly transport, and use it to derive an entire geometric toolbox for probability distributions. Despite this relatively abstract description, optimal transport theory answers many basic questions related to the way our economy works: In the “mines and factories” problem, the sand is distributed across an entire country, each grain of sand represents a unit of a useful raw resource; the target pile indicates where those resources are needed, typically in factories, where they are meant to be processed. In that scenario, one seeks the least costly way to move all these resources, knowing the entire logistic cost matrix needed to ship resources from any storage point to any factory. Transporting optimally two abstract distributions is also extremely relevant for mathematicians, in the sense that it defines a rich geometric structure on the space of probability distributions. That structure is canonical in the sense that it borrows, in arguably the most natural way, key geometric properties of the underlying “ground” space on which these distributions are defined. For instance, when the underlying space is Euclidean, key concepts s},
  file           = {:2019_Peyre.pdf:PDF},
  qualityassured = {qualityAssured},
  url            = {https://ideas.repec.org/p/crs/wpaper/2017-86.html},
}

@InProceedings{2019_Rieck_InProceedings,
  author         = {Rieck, Bastian and Bock, Christian and Borgwardt, Karsten},
  booktitle      = {Proceedings of the 36th International Conference on Machine Learning},
  title          = {{A} {P}ersistent {W}eisfeiler-{L}ehman {P}rocedure for {G}raph {C}lassification},
  year           = {2019},
  editor         = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  month          = {09--15 Jun},
  pages          = {5448--5458},
  publisher      = {PMLR},
  series         = {Proceedings of Machine Learning Research},
  volume         = {97},
  abstract       = {The Weisfeiler–Lehman graph kernel exhibits competitive performance in many graph classification tasks. However, its subtree features are not able to capture connected components and cycles, topological features known for characterising graphs. To extract such features, we leverage propagated node label information and transform unweighted graphs into metric ones. This permits us to augment the subtree features with topological information obtained using persistent homology, a concept from topological data analysis. Our method, which we formalise as a generalisation of Weisfeiler–Lehman subtree features, exhibits favourable classification accuracy and its improvements in predictive performance are mainly driven by including cycle information.},
  file           = {:2019_Rieck_PMLR.pdf:PDF;rieck19a.pdf:http\:/proceedings.mlr.press/v97/rieck19a/rieck19a.pdf:PDF},
  keywords       = {Weisfeiler-Lehman, Topological Data Analysis, Persistent Homology, Graph Classification, Cycles},
  qualityassured = {qualityAssured},
  url            = {https://proceedings.mlr.press/v97/rieck19a.html},
}

@InProceedings{2019_Schulz_InProceedings,
  author         = {Till Hendrik Schulz and Pascal Welke},
  title          = {On the necessity of graph kernel baselines - poster},
  year           = {2019},
  publisher      = {IEEE},
  file           = {:2019_Schulz_POSTER.pdf:PDF},
  qualityassured = {qualityAssured},
  url            = {https://gem-ecmlpkdd.github.io/archive/2019/papers/GEM2019_paper_17.pdf},
}

@InProceedings{2020_Srinivasan_InProceedings,
  author         = {Balasubramaniam Srinivasan and Bruno Ribeiro},
  title          = {{O}n the {E}quivalence between {P}ositional {N}ode {E}mbeddings and {S}tructural {G}raph {R}epresentations},
  year           = {2020},
  abstract       = {This work provides the first unifying theoretical framework for node (positional)
embeddings and structural graph representations, bridging methods like matrix
factorization and graph neural networks. Using invariant theory, we show that
the relationship between structural representations and node embeddings is anal-
ogous to that of a distribution and its samples. We prove that all tasks that can
be performed by node embeddings can also be performed by structural represen-
tations and vice-versa. We also show that the concept of transductive and induc-
tive learning is unrelated to node embeddings and graph representations, clearing
another source of confusion in the literature. Finally, we introduce new practi-
cal guidelines to generating and using node embeddings, which fixes significant
shortcomings of standard operating procedures used today.},
  archiveprefix  = {arXiv},
  eprint         = {1910.00452},
  eprinttype     = {arxiv},
  file           = {:2019_Srinivasan.pdf:PDF},
  primaryclass   = {cs.LG},
  qualityassured = {qualityAssured},
}

@InProceedings{2019_Togninalli_InProceedings,
  author         = {Togninalli, Matteo and Ghisu, Elisabetta and Llinares-L\'{o}pez, Felipe and Rieck, Bastian and Borgwardt, Karsten},
  booktitle      = {Advances in Neural Information Processing Systems},
  title          = {{W}asserstein {W}eisfeiler-{L}ehman {G}raph {K}ernels},
  year           = {2019},
  editor         = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  publisher      = {Curran Associates, Inc.},
  volume         = {32},
  abstract       = {Neural Information Processing Systems http://nips.cc/},
  file           = {:2019_Togninalli_NIPS.pdf:PDF},
  groups         = {GraphKernels},
  qualityassured = {qualityAssured},
  readstatus     = {read},
  url            = {https://proceedings.neurips.cc/paper_files/paper/2019/file/73fed7fd472e502d8908794430511f4d-Paper.pdf},
}

@InProceedings{2020_Chami_InProceedings,
  author         = {Ines Chami and Adva Wolf and Da-Cheng Juan and Frederic Sala and Sujith Ravi and Christopher Ré},
  title          = {{L}ow-{D}imensional {H}yperbolic {K}nowledge {G}raph {E}mbeddings},
  year           = {2020},
  abstract       = {Knowledge graph (KG) embeddings learn low-dimensional representations of entities and relations to predict missing facts. KGs often exhibit hierarchical and logical patterns which must be preserved in the embedding space. For hierarchical data, hyperbolic embedding methods have shown promise for high-fidelity and parsimonious representations. However, existing hyperbolic embedding methods do not account for the rich logical patterns in KGs. In this work, we introduce a class of hyperbolic KG embedding models that simultaneously capture hierarchical and logical patterns. Our approach combines hyperbolic reflections and rotations with attention to model complex relational patterns. Experimental results on standard KG benchmarks show that our method improves over previous Euclidean- and hyperbolic-based efforts by up to 6.1% in mean reciprocal rank (MRR) in low dimensions. Furthermore, we observe that different geometric transformations capture different types of relations while attention-based transformations generalize to multiple relations. In high dimensions, our approach yields new state-of-the-art MRRs of 49.6% on WN18RR and 57.7% on YAGO3-10.},
  archiveprefix  = {arXiv},
  eprint         = {2005.00545},
  file           = {:2020_Chami_CONF.pdf:PDF},
  groups         = {GraphKernels},
  primaryclass   = {cs.LG},
  qualityassured = {qualityAssured},
}

@InProceedings{2021_Cohen_InProceedings,
  author         = {Samuel Cohen and Michael Arbel and Marc Peter Deisenroth},
  title          = {{E}stimating {B}arycenters of {M}easures in {H}igh {D}imensions},
  year           = {2021},
  abstract       = {Proceedings of the International Conference on Machine Learning 2021},
  archiveprefix  = {arXiv},
  eprint         = {2007.07105},
  eprinttype     = {arxiv},
  file           = {:2020_Cohen_CONF.pdf:PDF},
  groups         = {ClusteringAlgorithms},
  keywords       = {Machine Learning, ICML},
  primaryclass   = {stat.ML},
  qualityassured = {qualityAssured},
}

@InProceedings{2003_Prakash_InProceedings,
  author         = {Vijay Prakash and Dwivedi1∗ Chaitanya and K. Joshi and vijaypra001@e.ntu.edu.sg chaitanya.joshi@ntu.edu.sg},
  title          = {{B}enchmarking {G}raph {N}eural {N}etworks},
  year           = {2003},
  file           = {:2020_Dwivedi_CONF.pdf:PDF},
  groups         = {GraphKernels},
  qualityassured = {qualityAssured},
  url            = {https://www.jmlr.org/papers/volume24/22-0567/22-0567.pdf},
}

@Book{2020_Hamilton_Book,
  author         = {William L. Hamilton},
  publisher      = {Springer International Publishing},
  title          = {Graph Representation Learning},
  year           = {2020},
  doi            = {10.1007/978-3-031-01588-5},
  file           = {:2020_Hamilton_BOOK.pdf:PDF},
  groups         = {Graphtheory, GraphKernels},
  qualityassured = {qualityAssured},
}

@InProceedings{2020_Hu_InProceedings,
  author         = {Weihua Hu and Matthias Fey and Marinka Zitnik and Yuxiao Dong and Hongyu Ren and Bowen Liu and Michele Catasta and Jure Leskovec},
  title          = {{O}pen {G}raph {B}enchmark: {D}atasets for {M}achine {L}earning on {G}raphs},
  year           = {2020},
  file           = {:2020_Hu_CONF.pdf:PDF},
  groups         = {GraphKernels},
  qualityassured = {qualityAssured},
  url            = {https://proceedings.neurips.cc/paper/2020/hash/fb60d411a5c5b72b2e7d3527cfc84fd0-Abstract.html},
}

@InProceedings{2020_Mirhoseini_InProceedings,
  author         = {Azalia Mirhoseini and Anna Goldie and Mustafa Yazgan and Joe Jiang and Ebrahim Songhori and Shen Wang and Young-Joon Lee and Eric Johnson and Omkar Pathak and Sungmin Bae and Azade Nazi and Jiwoo Pak and Andy Tong and Kavya Srinivasa and William Hang and Emre Tuncer and Anand Babu and Quoc V. Le and James Laudon and Richard Ho and Roger Carpenter and Jeff Dean},
  title          = {{C}hip {P}lacement with {D}eep {R}einforcement {L}earning},
  year           = {2020},
  abstract       = {In this work, we present a learning-based approach to chip placement, one of the most complex and time-consuming stages of the chip design process. Unlike prior methods, our approach has the ability to learn from past experience and improve over time. In particular, as we train over a greater number of chip blocks, our method becomes better at rapidly generating optimized placements for previously unseen chip blocks. To achieve these results, we pose placement as a Reinforcement Learning (RL) problem and train an agent to place the nodes of a chip netlist onto a chip canvas. To enable our RL policy to generalize to unseen blocks, we ground representation learning in the supervised task of predicting placement quality. By designing a neural architecture that can accurately predict reward across a wide variety of netlists and their placements, we are able to generate rich feature embeddings of the input netlists. We then use this architecture as the encoder of our policy and value networks to enable transfer learning. Our objective is to minimize PPA (power, performance, and area), and we show that, in under 6 hours, our method can generate placements that are superhuman or comparable on modern accelerator netlists, whereas existing baselines require human experts in the loop and take several weeks.},
  archiveprefix  = {arXiv},
  eprint         = {2004.10746},
  eprinttype     = {arxiv},
  file           = {:2020_Mirhoseini_CONF.pdf:PDF},
  primaryclass   = {cs.LG},
  qualityassured = {qualityAssured},
}

@InProceedings{2020_Morris_InProceedings,
  author         = {Christopher Morris and Nils M. Kriege and Franka Bause and Kristian Kersting and Petra Mutzel and Marion Neumann},
  title          = {{TUD}ataset: A collection of benchmark datasets for learning with graphs},
  year           = {2020},
  abstract       = {Graph Representation Learning and Beyond (GRL+), ICML 2020 Workshop},
  eprint         = {2007.08663},
  eprinttype     = {arxiv},
  file           = {:2020_Morris_CONF.pdf:PDF},
  groups         = {GraphKernels},
  keywords       = {graph learning, graph kernel, weisfeiler, leman, gnn, graph neural network, benchmark datasets},
  qualityassured = {qualityAssured},
}

@InProceedings{2020_SanchezGonzalez_InProceedings,
  author         = {Alvaro Sanchez-Gonzalez and Jonathan Godwin and Tobias Pfaff and Rex Ying and Jure Leskovec and Peter W. Battaglia},
  title          = {{L}earning to {S}imulate {C}omplex {P}hysics with {G}raph {N}etworks},
  year           = {2020},
  abstract       = {Proceedings of the International Conference on Machine Learning 2020},
  file           = {:2020_Sanchey-Gonzalez_PMLR.pdf:PDF},
  keywords       = {Machine Learning, Graph Neural Networks, Physical Simulation, Particle-based Fluid Simulation},
  qualityassured = {qualityAssured},
  url            = {https://proceedings.mlr.press/v119/sanchez-gonzalez20a.html},
}

@InProceedings{2020_Siglidis_InProceedings,
  author         = {Giannis Siglidis and Giannis Nikolentzos and Stratis Limnios and Christos Giatsidis and Konstantinos Skianis and Michalis Vazirgiannis},
  title          = {{G}ra{K}e{L}: {A} {G}raph {K}ernel {L}ibrary in {P}ython},
  year           = {2020},
  number         = {54},
  pages          = {1--5},
  volume         = {21},
  file           = {:2020_Siglidis_JMLR.pdf:PDF},
  groups         = {GraphKernels},
  journal        = {Journal of Machine Learning Research},
  keywords       = {graph similarity, graph kernels, scikit-learn, Python},
  qualityassured = {qualityAssured},
  url            = {http://jmlr.org/papers/v21/18-370.html},
}

@InProceedings{2021_Zhang_InProceedings,
  author         = {Muhan Zhang and Pan Li and Yinglong Xia and Kai Wang and Long Jin},
  title          = {{R}evisiting {G}raph {N}eural {N}etworks for {L}ink {P}rediction},
  year           = {2021},
  abstract       = {Graph neural networks (GNNs) have achieved great success in recent years. Three most common applications include node classification, link prediction, and graph classification. While there is rich literature on node classification and graph classification, GNNs for link prediction is relatively less studied and less understood. Two representative classes of methods exist: GAE and SEAL. GAE (Graph Autoencoder) first uses a GNN to learn node embeddings for all nodes, and then aggregates the embeddings of the source and target nodes as their link representation. SEAL extracts a subgraph around the source and target nodes, labels the nodes in the subgraph, and then uses a GNN to learn a link representation from the labeled subgraph. In this paper, we thoroughly discuss the differences between these two classes of methods, and conclude that simply aggregating \textit{node} embeddings does not lead to effective \textit{link} representations, while learning from \textit{properly labeled subgraphs} around links provides highly expressive and generalizable link representations. Experiments on the recent large-scale OGB link prediction datasets show that SEAL has up to 195\% performance gains over GAE methods, achieving new state-of-the-art results on 3 out of 4 datasets.},
  file           = {:2020_Zhang_CONF.pdf:PDF},
  qualityassured = {qualityAssured},
  url            = {https://openreview.net/forum?id=8q_ca26L1fz},
}

@InProceedings{2021_Flamary_InProceedings,
  author         = {Flamary, R\'{e}mi and Courty, Nicolas and Gramfort, Alexandre and Alaya, Mokhtar Z. and Boisbunon, Aur\'{e}lie and Chambon, Stanislas and Chapel, Laetitia and Corenflos, Adrien and Fatras, Kilian and Fournier, Nemo and Gautheron, L\'{e}o and Gayraud, Nathalie T. H. and Janati, Hicham and Rakotomamonjy, Alain and Redko, Ievgen and Rolet, Antoine and Schutz, Antony and Seguy, Vivien and Sutherland, Danica J. and Tavenard, Romain and Tong, Alexander and Vayer, Titouan},
  title          = {{POT}: {P}ython {O}ptimal {T}ransport},
  year           = {2021},
  month          = {jan},
  number         = {1},
  publisher      = {JMLR.org},
  volume         = {22},
  abstract       = {Optimal transport has recently been reintroduced to the machine learning community thanks in part to novel efficient optimization procedures allowing for medium to large scale applications. We propose a Python toolbox that implements several key optimal transport ideas for the machine learning community. The toolbox contains implementations of a number of founding works of OT for machine learning such as Sinkhorn algorithm and Wasserstein barycenters, but also provides generic solvers that can be used for conducting novel fundamental research. This toolbox, named POT for Python Optimal Transport, is open source with an MIT license.},
  articleno      = {78},
  doi            = {10.5555/3546258.3546336},
  file           = {:2021_Flamary_JMLR.pdf:PDF},
  issn           = {1532-4435},
  issue_date     = {January 2021},
  journal        = {J. Mach. Learn. Res.},
  keywords       = {divergence, domain adaptation, optimal transport, optimization},
  numpages       = {8},
  qualityassured = {qualityAssured},
}

@Misc{2021_Schulz_Misc,
  author         = {Schulz, Till Hendrik and Horváth, Tamás and Welke, Pascal and Wrobel, Stefan},
  title          = {A Generalized Weisfeiler-Lehman Graph Kernel},
  year           = {2021},
  abstract       = {more than it resembles T3, the Weisfeiler-Lehman ker-
The Weisfeiler-Lehman graph kernels are among the most nel [11] simply treats them all as unequal and is thus
prevalent graph kernels due to their remarkable time com- unable to quantify the apparent difference among the
plexity and predictive performance. Their key concept is
based on an implicit comparison of neighborhood repre- pairwise similarities between the unfolding trees.
senting trees with respect to equality (i.e., isomorphism). Motivated by these considerations, we relax the
This binary valued comparison is, however, arguably too above strictness by proposing a method which com-
rigid for defining suitable similarity measures over graphs.
To overcome this limitation, we propose a generalization of pares Weisfeiler-Lehman labels, or equivalently unfold-
Weisfeiler-Lehman graph kernels which takes into account ing trees, with regard to a much finer similarity measure
the similarity between trees rather than equality. We achieve than the binary valued one. More precisely, we employ
this using a specifically fitted variation of the well-known tree
edit distance which can efficiently be calculated. We em- a similarity between Weisfeiler-Lehman labels based on
pirically show that our approach significantly outperforms the concept of tree edit distances between their respec-
state-of-the-art methods in terms of predictive performance tive unfolding trees. These kind of distances provide
on datasets containing structurally more complex graphs be-
yond the typically considered molecular graphs. a natural comparison for trees. On an abstract level,},
  copyright      = {arXiv.org perpetual, non-exclusive license},
  doi            = {10.48550/ARXIV.2101.08104},
  file           = {:2021_Schulz_CONF.pdf:PDF},
  groups         = {GraphKernels},
  keywords       = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher      = {arXiv},
  qualityassured = {qualityAssured},
  url            = {https://ui.adsabs.harvard.edu/abs/2021arXiv210108104H/abstract},
}

@Article{2022_Schulz_Article,
  author         = {Schulz, Till and Welke, Pascal and Wrobel, Stefan},
  journal        = {Proceedings of the AAAI Conference on Artificial Intelligence},
  title          = {{G}raph {F}iltration {K}ernels},
  year           = {2022},
  month          = {Jun.},
  number         = {8},
  pages          = {8196-8203},
  volume         = {36},
  abstract       = {substructures in terms of equivalence. We refer to these ker-
nels as histogram kernels. While they prove to be successful},
  doi            = {10.1609/aaai.v36i8.20793},
  file           = {:2021_Schulz_CONFa.pdf:PDF},
  groups         = {GraphKernels},
  qualityassured = {qualityAssured},
  url            = {https://ojs.aaai.org/index.php/AAAI/article/view/20793},
}

@InProceedings{1968_Weisfeiler_InProceedings,
  author         = {Weisfeiler, Boris and Leman, Andrei},
  title          = {The reduction of a graph to canonical form and the algebra which appears therein},
  year           = {1968},
  number         = {9},
  pages          = {12--16},
  volume         = {2},
  abstract       = {We consider an algorithm for the reduction of a given finite multigraph Γ to
canonical form. Therein the new invariant of a graph appears — the algebra A(Γ). The
study of properties of the algebra A(Γ) turns out to be helpful in solving a number of
graph-theoretic problems. We pose and discuss some conjectures on the relation between
properties of the algebra A(Γ) and the automorphism group Aut(Γ) of a graph Γ. We give
an example of undirected graph Γ whose algebra A(Γ) coincides with the group algebra of
some noncommutative group.},
  file           = {:1968_Weisfeiler_CONF.pdf:PDF},
  groups         = {Graphtheory},
  journal        = {nti, Series},
  qualityassured = {qualityAssured},
  url            = {https://www.iti.zcu.cz/wl2018/pdf/wl_paper_translation.pdf},
}

@Article{1976_Ullmann_Article,
  author         = {Ullmann, Julian R.},
  journal        = {Journal of the ACM (JACM)},
  title          = {An algorithm for subgraph isomorphism},
  year           = {1976},
  month          = {jan},
  number         = {1},
  pages          = {31--42},
  volume         = {23},
  abstract       = {Subgraph isomorphism can be determined by means of a brute-force tree-search enu-
meration procedure. In this paper a new algorithm is introduced that attains efficiencyb y inferentially 
eliminatings uccessor nodes in the tree search. To assess the time actually taken by the new algomthm, 
subgraph isomorphism, chque detection, graph isomorphism, and directed graph isomorphism ex- 
periments have been carried out with random and with various nonrandom graphs.},
  doi            = {10.1145/321921.321925},
  file           = {:1976_Ullmann_CONF.pdf:PDF},
  groups         = {AppliedGraphtheory, Graphtheory},
  publisher      = {ACM New York, NY, USA},
  qualityassured = {qualityAssured},
  readstatus     = {read},
}

@Article{1980_Babai_Article,
  author         = {L{\'{a}}szl{\'{o}} Babai and Paul Erdo{\H{}}s and Stanley M. Selkow},
  journal        = {{SIAM} Journal on Computing},
  title          = {{R}andom {G}raph {I}somorphism},
  year           = {1980},
  month          = {aug},
  number         = {3},
  pages          = {628--635},
  volume         = {9},
  abstract       = {SIAM J. Comput. 1980.9:628-635},
  doi            = {10.1137/0209047},
  file           = {:1980_Babai_SIAM.pdf:PDF},
  groups         = {AppliedGraphtheory, Graphtheory},
  keywords       = {graph,isomorphism testing,canonical labeling,random graph,naive algorithm,average-case analysis,linear time,degree sequence of a graph},
  publisher      = {SIAM},
  qualityassured = {qualityAssured},
}

@Book{2007_Mitchell_Book,
  author         = {Mitchell, Tom Michael and others},
  publisher      = {McGraw-hill New York},
  title          = {Machine learning},
  year           = {2007},
  volume         = {1},
  file           = {:1983_Mitchell_BOOK.pdf:PDF},
  groups         = {MachineLearning},
  qualityassured = {qualityAssured},
  url            = {https://library.iitgn.ac.in/documents/library_files/2016/19032016.pdf},
}

@Article{1992_Cai_Article,
  author         = {Cai, Jin-Yi and F{\"u}rer, Martin and Immerman, Neil},
  journal        = {Combinatorica},
  title          = {An optimal lower bound on the number of variables for graph identification},
  year           = {1992},
  month          = {dec},
  number         = {4},
  pages          = {389--410},
  volume         = {12},
  doi            = {10.1007/bf01305232},
  file           = {:1992_Cai_IEEE.pdf:PDF},
  groups         = {AppliedGraphtheory, Graphtheory},
  publisher      = {Springer Science and Business Media {LLC}},
  qualityassured = {qualityAssured},
  readstatus     = {read},
  url            = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=e8151a322b62a37b03c105d0033c3775b00f1ee1},
}

@Article{1992_Wilkinson_Article,
  author         = {Wilkinson, Leland and others},
  journal        = {Retrieved February},
  title          = {{T}ree structured data analysis: {AID}, {CHAID} and {CART}},
  year           = {1992},
  pages          = {2008},
  volume         = {1},
  file           = {:1992_Wilkinson_CONF.pdf:PDF},
  groups         = {Graphtheory},
  qualityassured = {qualityAssured},
  url            = {https://www.researchgate.net/profile/Leland-Wilkinson/publication/228698437_Tree_structured_data_analysis_AID_CHAID_and_CART/links/55e72a2a08ae21d099c148c3/Tree-structured-data-analysis-AID-CHAID-and-CART.pdf},
}

@Article{1992_Zhang_Article,
  author         = {Zhang, Kaizhong and Statman, Rick and Shasha, Dennis},
  journal        = {Information processing letters},
  title          = {On the editing distance between unordered labeled trees},
  year           = {1992},
  number         = {3},
  pages          = {133--139},
  volume         = {42},
  file           = {:1992_Zhang_CONF.pdf:PDF},
  groups         = {AppliedGraphtheory, Graphtheory},
  keywords       = {Computational complexity, unordered trees},
  publisher      = {Elsevier},
  qualityassured = {qualityAssured},
  url            = {https://www.sciencedirect.com/science/article/pii/002001909290136J},
}

@InProceedings{1993_Zhang_InProceedings,
  author         = {Zhang, Kaizhong},
  booktitle      = {Combinatorial Pattern Matching: 4th Annual Symposium, CPM 93 Padova, Italy, June 2--4, 1993 Proceedings 4},
  title          = {A new editing based distance between unordered labeled trees},
  year           = {1993},
  organization   = {Springer},
  pages          = {254--265},
  doi            = {10.1007/BFb0029810},
  file           = {:1993_Zhang_CONF.pdf:PDF},
  groups         = {AppliedGraphtheory, Graphtheory},
  qualityassured = {qualityAssured},
}

@Article{1995_LeCun_Article,
  author         = {LeCun, Yann and Bengio, Yoshua and others},
  journal        = {The handbook of brain theory and neural networks},
  title          = {Convolutional networks for images, speech, and time series},
  year           = {1995},
  number         = {10},
  pages          = {1995},
  volume         = {3361},
  file           = {:1995_LeCun_CONF.pdf:PDF},
  groups         = {Convolutional networks, ConvolutionNetworks},
  publisher      = {Citeseer},
  qualityassured = {qualityAssured},
  url            = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=e26cc4a1c717653f323715d751c8dea7461aa105},
}

@Article{1998_Lecun_Article,
  author         = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  journal        = {Proceedings of the {IEEE}},
  title          = {Gradient-based learning applied to document recognition},
  year           = {1998},
  number         = {11},
  pages          = {2278--2324},
  volume         = {86},
  abstract       = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.},
  doi            = {10.1109/5.726791},
  file           = {:1998_Lecun_IEEE.pdf:PDF},
  groups         = {MachineLearning},
  publisher      = {Institute of Electrical and Electronics Engineers ({IEEE})},
  qualityassured = {qualityAssured},
  url            = {https://ieeexplore.ieee.org/abstract/document/726791/},
}

@Article{2003_Dobson_Article,
  author         = {Dobson, Paul D. and Doig, Andrew J.},
  journal        = {Journal of molecular biology},
  title          = {Distinguishing enzyme structures from non-enzymes without alignments},
  year           = {2003},
  number         = {4},
  pages          = {771--783},
  volume         = {330},
  doi            = {10.1016/S0022-2836(03)00628-4},
  file           = {:2003_Dobson_CONF.pdf:PDF},
  keywords       = {protein function prediction; structure; enzyme; machine *Corresponding author learning; structural genomics},
  publisher      = {Elsevier},
  qualityassured = {qualityAssured},
  url            = {https://www.sciencedirect.com/science/article/pii/S0022283603006284?casa_token=IX2kOcHWpSgAAAAA:7AxKoWztPZf1e993W32gyVYDnkEoihOl359BDY2EORGTaL4EpE2tZFtd-Y_sWjzkjZkXEikscNY},
}

@Misc{2003_Hsu_Misc,
  author         = {Hsu, Chih-Wei and Chang, Chih-Chung and Lin, Chih-Jen and others},
  title          = {A practical guide to support vector classification},
  year           = {2003},
  abstract       = {The support vector machine (SVM) is a popular classification technique.
However, beginners who are not familiar with SVM often get unsatisfactory
results since they miss some easy but significant steps. In this guide, we propose
a simple procedure which usually gives reasonable results.},
  file           = {:2003_Hsu_CONF.pdf:PDF},
  groups         = {Support Vector Machines, SupportVectorMachines},
  publisher      = {Taipei, Taiwan},
  qualityassured = {qualityAssured},
  url            = {http://www.datascienceassn.org/sites/default/files/Practical Guide to Support Vector Classification.pdf},
}

@Article{2003_Kashima_Article,
  author         = {Hisashi Kashima and Koji Tsuda and Akihiro Inokuchi},
  title          = {Marginalized kernels between labeled graphs},
  year           = {2003},
  abstract       = {Proceedings of the Twentieth International Conference on Machine Learning},
  file           = {:2003_Kashima_CONF.pdf:PDF},
  groups         = {GraphKernels},
  keywords       = {Compilation copyright ©2003, American Association for Artificial Intelligence. All rights reserved.},
  publisher      = {IEEE},
  qualityassured = {qualityAssured},
  url            = {https://pure.mpg.de/pubman/faces/ViewItemOverviewPage.jsp?itemId=item_3187440},
}

@InProceedings{2003_Nijssen_InProceedings,
  author         = {Siegfried Nijssen and Joost N. Kok},
  title          = {{E}fficient {D}iscovery of {F}requent {U}nordered {T}rees},
  year           = {2003},
  abstract       = {Recently, an algorithm called Freqt was introduced which
enumerates all frequent induced subtrees in an ordered data tree. We
propose a new algorithm for mining unordered frequent induced sub-
trees. We show that the complexity of enumerating unordered trees is
not higher than the complexity of enumerating ordered trees; a strategy
for determining the frequency of unordered trees is introduced.},
  file           = {:2003_Nijssen_CONF.pdf:PDF},
  groups         = {Graphtheory},
  qualityassured = {qualityAssured},
  url            = {https://dial.uclouvain.be/pr/boreal/object/boreal:186570/datastream/PDF_01/view},
}

@InProceedings{2004_Horvath_InProceedings,
  author         = {Horv{\'a}th, Tam{\'a}s and G{\"a}rtner, Thomas and Wrobel, Stefan},
  booktitle      = {Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining},
  title          = {Cyclic pattern kernels for predictive graph mining},
  year           = {2004},
  pages          = {158--167},
  abstract       = {With applications in biology, the world-wide web, and sev-
eral other areas, mining of graph-structured objects has re-
ceived signiﬁcant interest recently. One of the major re-
search directions in this ﬁeld is concerned with predictive
data mining in graph databases where each instance is repre-
sented by a graph. Some of the proposed approaches for this
task rely on the excellent classiﬁcation performance of sup-
port vector machines. To control the computational cost of
these approaches, the underlying kernel functions are based
on frequent patterns. In contrast to these approaches, we
propose a kernel function based on a natural set of cyclic and
tree patterns independent of their frequency, and discuss its
computational aspects. To practically demonstrate the ef-
fectiveness of our approach, we use the popular NCI-HIV
molecule dataset. Our experimental results show that cyclic
pattern kernels can be computed quickly and oﬀer predic-
tive performance superior to recent graph kernels based on
frequent patterns.},
  doi            = {10.1145/1014052.1014072},
  file           = {:2004_Horvath_KDD.pdf:PDF},
  groups         = {AppliedGraphtheory, GraphKernels},
  keywords       = {tured graphs while being efficient enough to be applied to},
  qualityassured = {qualityAssured},
}

@InProceedings{2004_Mahe_InProceedings,
  author         = {Mah{\'e}, Pierre and Ueda, Nobuhisa and Akutsu, Tatsuya and Perret, Jean-Luc and Vert, Jean-Philippe},
  booktitle      = {Proceedings of the twenty-first international conference on Machine learning},
  title          = {Extensions of marginalized graph kernels},
  year           = {2004},
  pages          = {70},
  publisher      = {{ACM} Press},
  abstract       = {tial drugs, require the analysis, comparison, and clas-
sification of these graphs. Among the many different},
  doi            = {10.1145/1015330.1015446},
  file           = {:2004_Mahe_ICML.pdf:PDF},
  groups         = {AppliedGraphtheory, GraphKernels},
  qualityassured = {qualityAssured},
}

@Article{2005_Bille_Article,
  author         = {Bille, Philip},
  journal        = {Theoretical computer science},
  title          = {A survey on tree edit distance and related problems},
  year           = {2005},
  month          = {jun},
  number         = {1-3},
  pages          = {217--239},
  volume         = {337},
  doi            = {10.1016/j.tcs.2004.12.030},
  file           = {:2005_Bille_TCS.pdf:PDF},
  groups         = {Graphtheory},
  keywords       = {Tree matching; Tree edit distance; Tree alignment; Tree inclusion},
  publisher      = {Elsevier},
  qualityassured = {qualityAssured},
}

@Article{2005_Borgwardt_Article,
  author         = {K. M. Borgwardt and C. S. Ong and S. Schonauer and S. V. N. Vishwanathan and A. J. Smola and H.-P. Kriegel},
  journal        = {Bioinformatics},
  title          = {Protein function prediction via graph kernels},
  year           = {2005},
  month          = {jun},
  number         = {Suppl 1},
  pages          = {i47--i56},
  volume         = {21},
  abstract       = {known function is consequently the basis of current function
Motivation: Computational approaches to protein function prediction (Whisstock and Lesk, 2003). A newly discovered
prediction infer protein function by finding proteins with sim- protein is predicted to exert the same function as the most
ilar sequence, structure, surface clefts, chemical properties, similar proteins in a database of known proteins. This simil-
amino acid motifs, interaction partners or phylogenetic pro- arity among proteins can be defined in a multitude of ways:
files. We present a new approach that combines sequential, two proteins can be regarded to be similar, if their sequences
structural and chemical information into one graph model of align well [e.g. PSI-BLAST (Altschul et al., 1997)], if their
proteins. We predict functional class membership of enzymes structures match well [e.g. DALI (Holm and Sander, 1996)],
and non-enzymes using graph kernels and support vector if both have common surface clefts or bindings sites [e.g.
machine classification on these protein graphs. CASTp (Binkowski et al., 2003)], similar chemical fea-
Results: Our graph model, derivable from protein sequence tures or common interaction partners [e.g. DIP (Xenarios
and structure only, is competitive with vector models that et al., 2002)], if both contain certain motifs of amino acids
require additional protein information, such as the size of (AAs) [e.g. Evolutionary Trace (Yao et al., 2003)] or if both
surface pockets. If we include this extra information into our appear in the same range of species (Pellegrini et al., 1999).
graph model, our classifier yields significantly higher accuracy An armada of protein function prediction systems that meas-
levels than the vector models. Hyperkernels allow us to select ure protein similarity by one of the conditions above has been
and to optimally combine the most relevant node attributes in developed. Each of these conditions is based on a biological
our protein graphs. We have laid the foundation for a protein hypothesis; e.g. structural similarity implies that two proteins
function prediction system that integrates protein information could share a common ancestor and that they both could per-
from various sources efficiently and effectively. form the same function as this common ancestor (Bartlett
Availability: More information available via www.dbs.ifi.lmu. et al., 2003).
de/Mitarbeiter/borgwardt.html. These assumptions are not universally valid. Hegyi and
Contact: borgwardt@dbs.ifi.lmu.de Gerstein (1999) showed that proteins with similar function},
  doi            = {10.1093/bioinformatics/bti1007},
  file           = {:2005_Borgwardt_CONF.pdf:PDF},
  groups         = {AppliedGraphtheory, GraphKernels},
  publisher      = {Oxford University Press ({OUP})},
  qualityassured = {qualityAssured},
}

@InProceedings{2005_Borgwardt_InProceedings,
  author         = {Borgwardt, K. M. and Kriegel, H. P.},
  booktitle      = {Fifth IEEE International Conference on Data Mining (ICDM'05)},
  title          = {Shortest-path kernels on graphs},
  year           = {2005},
  pages          = {8 pp.-},
  abstract       = {this purpose. However, kernels on these substructures are
either computationally expensive, sometimes even NP-hard},
  doi            = {10.1109/ICDM.2005.132},
  file           = {:2005_Borgwardt_IEEE.pdf:PDF},
  groups         = {GraphKernels},
  qualityassured = {qualityAssured},
  url            = {https://ieeexplore.ieee.org/abstract/document/1565664/},
}

@InProceedings{2005_Boughorbel_InProceedings,
  author         = {Boughorbel, S. and Tarel, J.-P. and Boujemaa, N.},
  booktitle      = {IEEE International Conference on Image Processing 2005},
  title          = {Generalized histogram intersection kernel for image recognition},
  year           = {2005},
  pages          = {III-161},
  volume         = {3},
  doi            = {10.1109/ICIP.2005.1530353},
  file           = {:2005_Boughorbel_IEEE.pdf:PDF},
  qualityassured = {qualityAssured},
  url            = {https://ieeexplore.ieee.org/abstract/document/1530353/},
}

@InProceedings{2005_Froehlich_InProceedings,
  author         = {Fr\"{o}hlich, Holger and Wegner, J\"{o}rg K. and Sieker, Florian and Zell, Andreas},
  booktitle      = {Proceedings of the 22nd International Conference on Machine Learning},
  title          = {{O}ptimal {A}ssignment {K}ernels for {A}ttributed {M}olecular {G}raphs},
  year           = {2005},
  address        = {New York, NY, USA},
  pages          = {225–232},
  publisher      = {Association for Computing Machinery},
  series         = {ICML '05},
  abstract       = {We propose a new kernel function for attributed molecular graphs, which is based on the idea of computing an optimal assignment from the atoms of one molecule to those of another one, including information on neighborhood, membership to a certain structural element and other characteristics for each atom. As a byproduct this leads to a new class of kernel functions. We demonstrate how the necessary computations can be carried out efficiently. Compared to marginalized graph kernels our method in some cases leads to a significant reduction of the prediction error. Further improvement can be gained, if expert knowledge is combined with our method. We also investigate a reduced graph representation of molecules by collapsing certain structural elements, like e.g. rings, into a single node of the molecular graph.},
  doi            = {10.1145/1102351.1102380},
  file           = {:2005_Froehlich_ICML.pdf:PDF},
  groups         = {GraphKernels},
  isbn           = {1595931805},
  location       = {Bonn, Germany},
  numpages       = {8},
  qualityassured = {qualityAssured},
  readstatus     = {read},
}

@InProceedings{2005_Yang_InProceedings,
  author         = {Yang, Rui and Kalnis, Panos and Tung, Anthony K. H.},
  booktitle      = {Proceedings of the 2005 ACM SIGMOD international conference on Management of data},
  title          = {Similarity evaluation on tree-structured data},
  year           = {2005},
  pages          = {754--765},
  abstract       = {and the linear representation of data. They allow the expres-},
  doi            = {10.1145/1066157.1066243},
  file           = {:2005_Yang_CONF.pdf:PDF},
  groups         = {AppliedGraphtheory, Graphtheory},
  qualityassured = {qualityAssured},
}

@Book{2006_Bishop_Book,
  author         = {Bishop, Christopher M. and Nasrabadi, Nasser M.},
  publisher      = {Springer},
  title          = {Pattern recognition and machine learning},
  year           = {2006},
  number         = {4},
  volume         = {4},
  file           = {:2006_Bishop_BOOK.pdf:PDF},
  groups         = {MachineLearning},
  qualityassured = {qualityAssured},
  url            = {https://link.springer.com/book/9780387310732},
}

@PhdThesis{2007_Borgwardt_PhdThesis,
  author         = {Karsten Michael Borgwardt},
  title          = {{G}raph {K}ernels},
  year           = {2007},
  file           = {:2007_Borgwardt_BOOK.pdf:PDF},
  groups         = {AppliedGraphtheory, GraphKernels},
  qualityassured = {qualityAssured},
}

@InProceedings{2007_Harchaoui_InProceedings,
  author         = {Harchaoui, Zaid and Bach, Francis},
  booktitle      = {2007 IEEE Conference on Computer Vision and Pattern Recognition},
  title          = {{I}mage {C}lassification with {S}egmentation {G}raph {K}ernels},
  year           = {2007},
  pages          = {1-8},
  doi            = {10.1109/CVPR.2007.383049},
  file           = {:2007_Harchaoui_IEEE.pdf:PDF},
  groups         = {GraphKernels},
  qualityassured = {qualityAssured},
  url            = {https://ieeexplore.ieee.org/abstract/document/4270074/},
}

@Article{2007_Wale_Article,
  author         = {Nikil Wale and Ian A. Watson and George Karypis},
  journal        = {Knowledge and Information Systems},
  title          = {Comparison of descriptor spaces for chemical compound retrieval and classification},
  year           = {2007},
  month          = {aug},
  number         = {3},
  pages          = {347--375},
  volume         = {14},
  abstract       = {In recent years the development of computational techniques that build models
to correctly assign chemical compounds to various classes or to retrieve potential drug-like
compounds has been an active area of research. Many of the best-performing techniques for
these tasks utilize a descriptor-based representation of the compound that captures various
aspects of the underlying molecular graph’s topology. In this paper we compare five dif-
ferent set of descriptors that are currently used for chemical compound classification. We
also introduce four different descriptors derived from all connected fragments present in the
molecular graphs primarily for the purpose of comparing them to the currently used des-
criptor spaces and analyzing what properties of descriptor spaces are helpful in providing
effective representation for molecular graphs. In addition, we introduce an extension to exis-
ting vector-based kernel functions to take into account the length of the fragments present
in the descriptors. We experimentally evaluate the performance of the previously introduced
and the new descriptors in the context of SVM-based classification and ranked-retrieval on
28 classification and retrieval problems derived from 18 datasets. Our experiments show that
for both of these tasks, two of the four descriptors introduced in this paper along with the
extended connectivity fingerprint based descriptors consistently and statistically outperform
previously developed schemes based on the widely used fingerprint- and Maccs keys-based
descriptors, as well as recently introduced descriptors obtained by mining and analyzing the
structure of the molecular graphs.},
  doi            = {10.1007/s10115-007-0103-5},
  file           = {:2007_Wale_CONF.pdf:PDF},
  publisher      = {Springer Science and Business Media {LLC}},
  qualityassured = {qualityAssured},
}

@Article{2008_Hofmann_Article,
  author         = {Thomas Hofmann and Bernhard Schölkopf and Alexander J. Smola},
  journal        = {The Annals of Statistics},
  title          = {Kernel methods in machine learning},
  year           = {2008},
  month          = {jun},
  number         = {3},
  volume         = {36},
  abstract       = {The Annals of Statistics, 2008, Vol.36, No.3, 1171-1220},
  doi            = {10.1214/009053607000000677},
  file           = {:2008_Hofmann_CONF.pdf:PDF},
  groups         = {MachineLearning},
  publisher      = {Institute of Mathematical Statistics},
  qualityassured = {qualityAssured},
}

@InProceedings{2008_Kondor_InProceedings,
  author         = {Risi Kondor and Karsten M. Borgwardt},
  booktitle      = {Proceedings of the 25th international conference on Machine learning - {ICML} {\textquotesingle}08},
  title          = {{T}he {S}kew {S}pectrum of {G}raphs},
  year           = {2008},
  publisher      = {{ACM} Press},
  abstract       = {Given a graph G, the two main lines of research that
have emerged to address the above problem focus re-},
  doi            = {10.1145/1390156.1390219},
  file           = {:2008_Kondor_ICML.pdf:PDF},
  groups         = {AppliedGraphtheory, Graphtheory},
  qualityassured = {qualityAssured},
}

@Article{2008_Mahe_Article,
  author         = {Pierre Mah{\'{e}} and Jean-Philippe Vert},
  journal        = {Machine Learning},
  title          = {Graph kernels based on tree patterns for molecules},
  year           = {2008},
  month          = {oct},
  number         = {1},
  pages          = {3--35},
  volume         = {75},
  abstract       = {Motivated by chemical applications, we revisit and extend a family of positive
definite kernels for graphs based on the detection of common subtrees, initially proposed by
Ramon and Gärtner (Proceedings of the first international workshop on mining graphs, trees
and sequences, pp. 65–74, 2003). We propose new kernels with a parameter to control the
complexity of the subtrees used as features to represent the graphs. This parameter allows to
smoothly interpolate between classical graph kernels based on the count of common walks,
on the one hand, and kernels that emphasize the detection of large common subtrees, on the
other hand. We also propose two modular extensions to this formulation. The first extension
increases the number of subtrees that define the feature space, and the second one removes
noisy features from the graph representations. We validate experimentally these new kernels
on problems of toxicity and anti-cancer activity prediction for small molecules with support
vector machines.},
  doi            = {10.1007/s10994-008-5086-2},
  file           = {:2008_Mahé_CONF.pdf:PDF},
  groups         = {AppliedGraphtheory, GraphKernels},
  keywords       = {Graph kernels · Support vector machines · Chemoinformatics},
  publisher      = {Springer Science and Business Media {LLC}},
  qualityassured = {qualityAssured},
}

@InProceedings{2009_Kondor_InProceedings,
  author         = {Risi Kondor and Nino Shervashidze and Karsten M. Borgwardt},
  booktitle      = {Proceedings of the 26th Annual International Conference on Machine Learning - {ICML} {\textquotesingle}09},
  title          = {The graphlet spectrum},
  year           = {2009},
  publisher      = {{ACM} Press},
  abstract       = {In this paper, we overcome these two limitations by},
  doi            = {10.1145/1553374.1553443},
  file           = {:2009_Kondor_ICML.pdf:PDF},
  groups         = {AppliedGraphtheory, MachineLearning},
  qualityassured = {qualityAssured},
}

@Article{2008_Kulis_Article,
  author         = {Brian Kulis and Sugato Basu and Inderjit Dhillon and Raymond Mooney},
  journal        = {Machine Learning},
  title          = {Semi-supervised graph clustering: a kernel approach},
  year           = {2008},
  month          = {sep},
  number         = {1},
  pages          = {1--22},
  volume         = {74},
  abstract       = {Semi-supervised clustering algorithms aim to improve clustering results using
limited supervision. The supervision is generally given as pairwise constraints; such con-
straints are natural for graphs, yet most semi-supervised clustering algorithms are designed
for data represented as vectors. In this paper, we unify vector-based and graph-based ap-
proaches. We first show that a recently-proposed objective function for semi-supervised
clustering based on Hidden Markov Random Fields, with squared Euclidean distance and
a certain class of constraint penalty functions, can be expressed as a special case of the
weighted kernel k-means objective (Dhillon et al., in Proceedings of the 10th International
Conference on Knowledge Discovery and Data Mining, 2004a). A recent theoretical con-
nection between weighted kernel k-means and several graph clustering objectives enables
us to perform semi-supervised clustering of data given either as vectors or as a graph. For
graph data, this result leads to algorithms for optimizing several new semi-supervised graph
clustering objectives. For vector data, the kernel approach also enables us to find clusters
with non-linear boundaries in the input data space. Furthermore, we show that recent work
on spectral learning (Kamvar et al., in Proceedings of the 17th International Joint Confer-
ence on Artificial Intelligence, 2003) may be viewed as a special case of our formulation.
We empirically show that our algorithm is able to outperform current state-of-the-art semi-
supervised algorithms on both vector-based and graph-based data sets.},
  doi            = {10.1007/s10994-008-5084-4},
  file           = {:2009_Kulis_SpringerMachineLearning.pdf:PDF},
  keywords       = {Semi-supervised clustering · Kernel k-means · Graph clustering · Spectral learning},
  publisher      = {Springer Science and Business Media {LLC}},
  qualityassured = {qualityAssured},
}

@Article{2009_Scarselli_Article,
  author         = {Franco Scarselli and Marco Gori and Ah Chung Tsoi and Markus Hagenbuchner and Gabriele Monfardini},
  journal        = {{IEEE} Transactions on Neural Networks},
  title          = {{T}he {G}raph {N}eural {N}etwork {M}odel},
  year           = {2009},
  month          = {jan},
  number         = {1},
  pages          = {61--80},
  volume         = {20},
  doi            = {10.1109/tnn.2008.2005605},
  file           = {:2009_Scarselli_IEEE.pdf:PDF},
  groups         = {Graph Neural Networks, AppliedGraphtheory, GraphKernels},
  publisher      = {Institute of Electrical and Electronics Engineers ({IEEE})},
  qualityassured = {qualityAssured},
}

@InProceedings{2009_NinoShervashidze_InProceedings,
  author         = {Nino Shervashidze, Karsten M. Borgwardt},
  title          = {Fast subtree kernels on graphs},
  year           = {2009},
  volume         = {22},
  abstract       = {Neural Information Processing Systems http://nips.cc/},
  file           = {:2009_Shervashidze_NIPS.pdf:PDF},
  groups         = {AppliedGraphtheory, GraphKernels},
  journal        = {Advances in neural information processing systems},
  qualityassured = {qualityAssured},
  readstatus     = {read},
  url            = {https://proceedings.neurips.cc/paper/3813-fast-subtree-kernels-on-graphs},
}

@InProceedings{2010_FabrizioCosta_InProceedings,
  author         = {Fabrizio Costa, Kurt De Grave},
  title          = {{F}ast {N}eighborhood {S}ubgraph {P}airwise {D}istance {K}ernel},
  year           = {2010},
  abstract       = {performance (Ben-David et al., 2002). Possible reme-},
  file           = {:2010_Costa_ICML.pdf:PDF},
  groups         = {Graph Kernels, GraphKernels},
  keywords       = {graph kernel, chemoinformatics, molecular graph},
  qualityassured = {qualityAssured},
}

@InProceedings{2011_Bonneel_InProceedings,
  author         = {Nicolas Bonneel and Michiel van de Panne and Sylvain Paris and Wolfgang Heidrich},
  title          = {{D}isplacement {I}nterpolation {U}sing {L}agrangian {M}ass {T}ransport},
  year           = {2011},
  abstract       = {1 Introduction},
  file           = {:2011_Bonneel_SIGGRAPH.pdf:PDF},
  keywords       = {displacement interpolation, mass transport rection is, subjectively speaking, better defined as having a single},
  qualityassured = {qualityAssured},
}

@Article{2011_Chang_Article,
  author         = {Chih-Chung Chang and Chih-Jen Lin},
  journal        = {{ACM} Transactions on Intelligent Systems and Technology},
  title          = {{LIBSVM}},
  year           = {2011},
  month          = {apr},
  number         = {3},
  pages          = {1--27},
  volume         = {2},
  doi            = {10.1145/1961189.1961199},
  file           = {:2011_Chang_ACM.pdf:PDF},
  publisher      = {Association for Computing Machinery ({ACM})},
  qualityassured = {qualityAssured},
}

@Article{2011_Shervashidze_Article,
  author         = {Shervashidze, Nino and Schweitzer, Pascal and Van Leeuwen, Erik Jan and Mehlhorn, Kurt and Borgwardt, Karsten M.},
  journal        = {Journal of Machine Learning Research},
  title          = {Weisfeiler-lehman graph kernels.},
  year           = {2011},
  number         = {9},
  volume         = {12},
  file           = {:2011_Shervashidze_JMLR.pdf:PDF},
  groups         = {Graph Kernels, GraphKernels},
  keywords       = {graph kernels, graph classification, similarity measures for graphs, Weisfeiler-Lehman algorithm},
  qualityassured = {qualityAssured},
  readstatus     = {read},
  url            = {https://www.jmlr.org/papers/volume12/shervashidze11a/shervashidze11a.pdf},
}

@Article{2011_Wang_Article,
  author         = {Wang, Haizhou and Song, Mingzhou},
  journal        = {The R journal},
  title          = {Ckmeans. 1d. dp: optimal k-means clustering in one dimension by dynamic programming},
  year           = {2011},
  number         = {2},
  pages          = {29},
  volume         = {3},
  file           = {:2011_Wang_CONF.pdf:PDF},
  publisher      = {NIH Public Access},
  qualityassured = {qualityAssured},
  url            = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5148156/},
}

@Article{2012_Jovanovic_Article,
  author         = {Irena Jovanovi{\'{c}} and Zoran Stani{\'{c}}},
  journal        = {Linear Algebra and its Applications},
  title          = {Spectral distances of graphs},
  year           = {2012},
  month          = {mar},
  number         = {5},
  pages          = {1425--1435},
  volume         = {436},
  abstract       = {Linear Algebra and Its Applications, 436 (2012) 1425-1435. doi:10.1016/j.laa.2011.08.019},
  doi            = {10.1016/j.laa.2011.08.019},
  file           = {:2012_Jovanovic_ELSEVIER.pdf:PDF},
  groups         = {AppliedGraphtheory, Graphtheory},
  keywords       = {Spectral distance, Adjacency matrix, Graph energy, Cospectrality measure, Spectral diameter},
  publisher      = {Elsevier {BV}},
  qualityassured = {qualityAssured},
}

@InProceedings{2012_NilsKriege_InProceedings,
  author         = {Nils Kriege, Petra Mutzel},
  title          = {{S}ubgraph {M}atching {K}ernels for {A}ttributed {G}raphs},
  year           = {2012},
  abstract       = {Proceedings of the International Conference on Machine Learning 2010},
  eprint         = {1206.6483},
  file           = {:2012_Kriege_CONF.pdf:PDF},
  groups         = {Graph Kernels, GraphKernels},
  keywords       = {graph matching, common subgraph, graph kernel, machine learning, ICML},
  qualityassured = {qualityAssured},
}

@Article{2013_Bruna_Article,
  author         = {Bruna, Joan and Zaremba, Wojciech and Szlam, Arthur and LeCun, Yann},
  journal        = {arXiv preprint arXiv:1312.6203},
  title          = {Spectral networks and locally connected networks on graphs},
  year           = {2013},
  eprint         = {1312.6203},
  eprinttype     = {arxiv},
  file           = {:2013_Bruna_CONF.pdf:PDF},
  groups         = {Graph Neural Networks, Graphtheory},
  qualityassured = {qualityAssured},
}

@Article{2013_Oury_Article,
  author         = {Nicolas Oury and Michael Pedersen and Rasmus Petersen},
  journal        = {Electronic Proceedings in Theoretical Computer Science},
  title          = {{C}anonical {L}abelling of {S}ite {G}raphs},
  year           = {2013},
  month          = {jun},
  pages          = {13--28},
  volume         = {116},
  abstract       = {We investigate algorithms for canonical labelling of site graphs, i.e. graphs in which edges bind vertices on sites with locally unique names. We first show that the problem of canonical labelling of site graphs reduces to the problem of canonical labelling of graphs with edge colourings. We then present two canonical labelling algorithms based on edge enumeration, and a third based on an extension of Hopcroft's partition refinement algorithm. All run in quadratic worst case time individually. However, one of the edge enumeration algorithms runs in sub-quadratic time for graphs with "many" automorphisms, and the partition refinement algorithm runs in sub-quadratic time for graphs with "few" bisimulation equivalences. This suite of algorithms was chosen based on the expectation that graphs fall in one of those two categories. If that is the case, a combined algorithm runs in sub-quadratic worst case time. Whether this expectation is reasonable remains an interesting open problem.},
  doi            = {10.4204/eptcs.116.3},
  file           = {:2013_Oury_EPTCS.pdf:PDF},
  groups         = {AppliedGraphtheory, Graphtheory},
  publisher      = {Open Publishing Association},
  qualityassured = {qualityAssured},
}

@Article{2014_Wang_Article,
  author         = {Wang, Zhe and Xue, Xiangyang},
  journal        = {Support vector machines applications},
  title          = {Multi-class support vector machine},
  year           = {2014},
  pages          = {23--48},
  abstract       = {Support vector machine (SVM) was initially designed for binary
classification. To extend SVM to the multi-class scenario, a number of classification
models were proposed such as the one by Crammer and Singer (J Mach Learn Res
2:265–292, 2001). However, the number of variables in Crammer and Singer’s dual
problem is the product of the number of samples (l) by the number of classes
(k), which produces a large computational complexity. This chapter sorts the
existing classical techniques for multi-class SVM into the indirect and direct ones
and further gives the comparison for them in terms of theory and experiments.
Especially, this chapter exhibits a new Simplified Multi-class SVM (SimMSVM)
that reduces the size of the resulting dual problem from l × k to l by introducing
a relaxed classification error bound. The experimental discussion demonstrates
that the SimMSVM approach can greatly speed up the training process, while
maintaining a competitive classification accuracy.},
  doi            = {10.1007/978-3-319-02300-7__2,},
  file           = {:2014_Wang_BOOK.pdf:PDF},
  groups         = {Support Vector Machines},
  publisher      = {Springer},
  qualityassured = {qualityAssured},
}

@Article{2015_Duvenaud_Article,
  author         = {Duvenaud, David K. and Maclaurin, Dougal and Iparraguirre, Jorge and Bombarell, Rafael and Hirzel, Timothy and Aspuru-Guzik, Al{\'a}n and Adams, Ryan P.},
  journal        = {Advances in neural information processing systems},
  title          = {Convolutional networks on graphs for learning molecular fingerprints},
  year           = {2015},
  volume         = {28},
  file           = {:2015_Duvenaud_NIPS.pdf:PDF},
  groups         = {Graph Neural Networks, Convolutional networks, ConvolutionNetworks, GraphKernels},
  qualityassured = {qualityAssured},
  url            = {https://proceedings.neurips.cc/paper/2015/hash/f9be311e65d81a9ad8150a60844bb94c-Abstract.html},
}

@InProceedings{2015_Feragen_InProceedings,
  author         = {Aasa Feragen and Francois Lauze and Soren Hauberg},
  booktitle      = {2015 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
  title          = {Geodesic exponential kernels: When curvature and linearity conflict},
  year           = {2015},
  month          = {jun},
  publisher      = {{IEEE}},
  abstract       = {2015 IEEE Conference on Computer Vision and Pattern Recognition},
  doi            = {10.1109/cvpr.2015.7298922},
  file           = {:2015_Feragen_IEEE.pdf:PDF},
  qualityassured = {qualityAssured},
}

@Article{2015_Xu_Article,
  author         = {Xu, Hangjun},
  journal        = {arXiv preprint arXiv:1508.03381},
  title          = {An algorithm for comparing similarity between two trees},
  year           = {2015},
  eprint         = {1508.03381},
  eprinttype     = {arxiv},
  file           = {:2015_Xu_THESIS.pdf:PDF},
  groups         = {AppliedGraphtheory, Graphtheory},
  qualityassured = {qualityAssured},
}

@InProceedings{2016_Battaglia_InProceedings,
  author         = {Battaglia, Peter and Pascanu, Razvan and Lai, Matthew and Jimenez Rezende, Danilo and kavukcuoglu, koray},
  booktitle      = {Advances in Neural Information Processing Systems},
  title          = {{I}nteraction {N}etworks for {L}earning about {O}bjects, {R}elations and {P}hysics},
  year           = {2016},
  editor         = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
  publisher      = {Curran Associates, Inc.},
  volume         = {29},
  abstract       = {Reasoning about objects, relations, and physics is central to human intelligence, and a key goal of artificial intelligence. Here we introduce the interaction network, a model which can reason about how objects in complex systems interact, supporting dynamical predictions, as well as inferences about the abstract properties of the system. Our model takes graphs as input, performs object- and relation-centric reasoning in a way that is analogous to a simulation, and is implemented using deep neural networks. We evaluate its ability to reason about several challenging physical domains: n-body problems, rigid-body collision, and non-rigid dynamics. Our results show it can be trained to accurately simulate the physical trajectories of dozens of objects over thousands of time steps, estimate abstract quantities such as energy, and generalize automatically to systems with different numbers and configurations of objects and relations. Our interaction network implementation is the first general-purpose, learnable physics engine, and a powerful general framework for reasoning about object and relations in a wide variety of complex real-world domains.},
  eprint         = {1612.00222},
  file           = {:2016_Battaglia_NIPS.pdf:PDF},
  qualityassured = {qualityAssured},
  url            = {https://proceedings.neurips.cc/paper_files/paper/2016/file/3147da8ab4a0437c15ef51a5cc7f2dc4-Paper.pdf},
}

@InProceedings{2016_Defferrard_InProceedings,
  author         = {Defferrard, Micha\"{e}l and Bresson, Xavier and Vandergheynst, Pierre},
  booktitle      = {Advances in Neural Information Processing Systems},
  title          = {{C}onvolutional {N}eural {N}etworks on {G}raphs with {F}ast {L}ocalized {S}pectral {F}iltering},
  year           = {2016},
  editor         = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
  publisher      = {Curran Associates, Inc.},
  volume         = {29},
  abstract       = {In this work, we are interested in generalizing convolutional neural networks (CNNs) from low-dimensional regular grids, where image, video and speech are represented, to high-dimensional irregular domains, such as social networks, brain connectomes or words’ embedding, represented by graphs. We present a formulation of CNNs in the context of spectral graph theory, which provides the necessary mathematical background and efficient numerical schemes to design fast localized convolutional filters on graphs. Importantly, the proposed technique offers the same linear computational complexity and constant learning complexity as classical CNNs, while being universal to any graph structure. Experiments on MNIST and 20NEWS demonstrate the ability of this novel deep learning system to learn local, stationary, and compositional features on graphs.},
  eprint         = {1606.09375},
  file           = {:2016_Defferrard_NIPS.pdf:PDF},
  groups         = {ConvolutionNetworks, GraphKernels},
  qualityassured = {qualityAssured},
  url            = {https://proceedings.neurips.cc/paper_files/paper/2016/file/04df4d434d481c5bb723be1b6df1ee65-Paper.pdf},
}

@Article{2016_Kriege_Article,
  author         = {Kriege, Nils M. and Giscard, Pierre-Louis and Wilson, Richard},
  journal        = {Advances in neural information processing systems},
  title          = {On valid optimal assignment kernels and applications to graph classification},
  year           = {2016},
  volume         = {29},
  file           = {:2016_Kriege_NIPS.pdf:PDF},
  groups         = {GraphKernels},
  qualityassured = {qualityAssured},
  url            = {https://proceedings.neurips.cc/paper/2016/hash/0efe32849d230d7f53049ddc4a4b0c60-Abstract.html},
}

@Article{2017_Bresson_Article,
  author         = {Bresson, Xavier and Laurent, Thomas},
  journal        = {arXiv preprint arXiv:1711.07553},
  title          = {Residual gated graph convnets},
  year           = {2017},
  eprint         = {1711.07553},
  eprinttype     = {arxiv},
  file           = {:2017_Bresson_CONF.pdf:PDF},
  groups         = {Graphtheory},
  qualityassured = {qualityAssured},
}

@InProceedings{2017_Gilmer_InProceedings,
  author         = {Justin Gilmer and Samuel S. Schoenholz and Patrick F. Riley and Oriol Vinyals and George E. Dahl},
  booktitle      = {Proceedings of the 34th International Conference on Machine Learning},
  title          = {{N}eural {M}essage {P}assing for {Q}uantum {C}hemistry},
  year           = {2017},
  editor         = {Precup, Doina and Teh, Yee Whye},
  month          = {06--11 Aug},
  pages          = {1263--1272},
  publisher      = {PMLR},
  series         = {Proceedings of Machine Learning Research},
  volume         = {70},
  abstract       = {Supervised learning on molecules has incredible potential to be useful in chemistry, drug discovery, and materials science. Luckily, several promising and closely related neural network models invariant to molecular symmetries have already been described in the literature. These models learn a message passing algorithm and aggregation procedure to compute a function of their entire input graph. At this point, the next step is to find a particularly effective variant of this general approach and apply it to chemical prediction benchmarks until we either solve them or reach the limits of the approach. In this paper, we reformulate existing models into a single common framework we call Message Passing Neural Networks (MPNNs) and explore additional novel variations within this framework. Using MPNNs we demonstrate state of the art results on an important molecular property prediction benchmark; these results are strong enough that we believe future work should focus on datasets with larger molecules or more accurate ground truth labels.},
  file           = {:2017_Gilmer_InProceedings.pdf:PDF;gilmer17a.pdf:http\:/proceedings.mlr.press/v70/gilmer17a/gilmer17a.pdf:PDF},
  qualityassured = {qualityAssured},
  url            = {https://proceedings.mlr.press/v70/gilmer17a.html},
}

@Article{2017_Griffa_Article,
  author         = {Alessandra Griffa and Benjamin Ricaud and Kirell Benzi and Xavier Bresson and Alessandro Daducci and Pierre Vandergheynst and Jean-Philippe Thiran and Patric Hagmann},
  journal        = {NeuroImage},
  title          = {Transient networks of spatio-temporal connectivity map communication pathways in brain functional systems},
  year           = {2017},
  issn           = {1053-8119},
  pages          = {490-502},
  volume         = {155},
  abstract       = {The study of brain dynamics enables us to characterize the time-varying functional connectivity among distinct neural groups. However, current methods suffer from the absence of structural connectivity information. We propose to integrate infra-slow neural oscillations and anatomical-connectivity maps, as derived from functional and diffusion MRI, in a multilayer-graph framework that captures transient networks of spatio-temporal connectivity. These networks group anatomically wired and temporary synchronized brain regions and encode the propagation of functional activity on the structural connectome. In a group of 71 healthy subjects, we find that these transient networks demonstrate power-law spatial and temporal size, globally organize into well-known functional systems and describe wave-like trajectories of activation across anatomically connected regions. Within the transient networks, activity propagates through polysynaptic paths that include selective ensembles of structural connections and differ from the structural shortest paths. In the light of the communication-through-coherence principle, the identified spatio-temporal networks could encode communication channels' selection and neural assemblies, which deserves further attention. This work contributes to the understanding of brain structure-function relationships by considering the time-varying nature of resting-state interactions on the axonal scaffold, and it offers a convenient framework to study large-scale communication mechanisms and functional dynamics.},
  doi            = {10.1016/j.neuroimage.2017.04.015},
  file           = {:2017_Griffa_Article.pdf:PDF},
  keywords       = {Resting-state fMRI, Diffusion MRI, Brain connectivity, Multilayer network, Temporal network, Brain dynamics, Point-process, Communication-through-coherence, Spatio-temporal connectome},
  qualityassured = {qualityAssured},
  url            = {https://www.sciencedirect.com/science/article/pii/S105381191730304X},
}

@InProceedings{2017_Hamilton_InProceedings,
  author         = {Hamilton, Will and Ying, Zhitao and Leskovec, Jure},
  booktitle      = {Advances in Neural Information Processing Systems},
  title          = {{I}nductive {R}epresentation {L}earning on {L}arge {G}raphs},
  year           = {2017},
  editor         = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
  publisher      = {Curran Associates, Inc.},
  volume         = {30},
  abstract       = {Low-dimensional embeddings of nodes in large graphs have proved extremely useful in a variety of prediction tasks, from content recommendation to identifying protein functions. However, most existing approaches require that all nodes in the graph are present during training of the embeddings; these previous approaches are inherently transductive and do not naturally generalize to unseen nodes. Here we present GraphSAGE, a general, inductive framework that leverages node feature information (e.g., text attributes) to efficiently generate node embeddings. Instead of training individual embeddings for each node, we learn a function that generates embeddings by sampling and aggregating features from a node's local neighborhood. Our algorithm outperforms strong baselines on three inductive node-classification benchmarks: we classify the category of unseen nodes in evolving information graphs based on citation and Reddit post data, and we show that our algorithm generalizes to completely unseen graphs using a multi-graph dataset of protein-protein interactions.},
  eprint         = {1706.02216},
  file           = {:2017_Hamilton_NIPS.pdf:PDF},
  groups         = {GraphKernels},
  qualityassured = {qualityAssured},
  url            = {https://proceedings.neurips.cc/paper_files/paper/2017/file/5dd9db5e033da9c6fb5ba83c7a7ebea9-Paper.pdf},
}

@Article{2017_Marcheggiani_Article,
  author         = {Marcheggiani, Diego and Titov, Ivan},
  journal        = {arXiv preprint arXiv:1703.04826},
  title          = {Encoding sentences with graph convolutional networks for semantic role labeling},
  year           = {2017},
  doi            = {10.18653/v1/d17-1159},
  eprint         = {1703.04826},
  eprinttype     = {arxiv},
  file           = {:2017_Marcheggiani_CONF.pdf:PDF},
  qualityassured = {qualityAssured},
}

@Article{2018_Krakovna_Article,
  author         = {Krakovna, Viktoriya and Orseau, Laurent and Martic, Miljan and Legg, Shane},
  title          = {Measuring and avoiding side effects using relative reachability},
  year           = {2018},
  month          = {06},
  abstract       = {How can we design reinforcement learning agents that avoid causing unnecessary disruptions to their environment? We argue that current approaches to penalizing side effects can introduce bad incentives in tasks that require irreversible actions, and in environments that contain sources of change other than the agent. For example, some approaches give the agent an incentive to prevent any irreversible changes in the environment, including the actions of other agents. We introduce a general definition of side effects, based on relative reachability of states compared to a default state, that avoids these undesirable incentives. Using a set of gridworld experiments illustrating relevant scenarios, we empirically compare relative reachability to penalties based on existing definitions and show that it is the only penalty among those tested that produces the desired behavior in all the scenarios.},
  comment        = {RL Project Bachelor Thesis - Alex Roucka

See also "Penalizing side effects using stepwise relative reachability" by Krakovna et al.},
  groups         = {Alex Roucka},
  qualityassured = {qualityAssured},
  readstatus     = {read},
  url            = {https://www.researchgate.net/publication/325557348_Measuring_and_avoiding_side_effects_using_relative_reachability},
}

@InProceedings{2020_Turner_InProceedings,
  author     = {Turner, Alex and Ratzlaff, Neale and Tadepalli, Prasad},
  booktitle  = {Advances in Neural Information Processing Systems},
  title      = {{A}voiding {S}ide {E}ffects in {C}omplex {E}nvironments},
  year       = {2020},
  editor     = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
  pages      = {21406--21415},
  publisher  = {Curran Associates, Inc.},
  volume     = {33},
  abstract   = {Reward function specification can be difficult. Rewarding the agent for making a widget may be easy, but penalizing the multitude of possible negative side effects is hard. In toy environments, Attainable Utility Preservation (AUP) avoided side effects by penalizing shifts in the ability to achieve randomly generated goals. We scale this approach to large, randomly generated environments based on Conway's Game of Life. By preserving optimal value for a single randomly generated reward function, AUP incurs modest overhead while leading the agent to complete the specified task and avoid many side effects. Videos and code are available at https://avoiding-side-effects.github.io/.},
  comment    = {RL Project Bachelor Thesis - Alex Roucka},
  groups     = {Alex Roucka},
  readstatus = {skimmed},
  url        = {https://proceedings.neurips.cc/paper_files/paper/2020/file/f50a6c02a3fc5a3a5d4d9391f05f3efc-Paper.pdf},
}

@Misc{2018_Krakovna_Misc,
  author     = {Krakovna, Victoria and Orseau, Laurent and Kumar, Ramana and Martic, Miljan and Legg, Shane},
  title      = {Penalizing side effects using stepwise relative reachability},
  year       = {2018},
  abstract   = {How can we design safe reinforcement learning agents that avoid unnecessary disruptions to their environment? We show that current approaches to penalizing side effects can introduce bad incentives, e.g. to prevent any irreversible changes in the environment, including the actions of other agents. To isolate the source of such undesirable incentives, we break down side effects penalties into two components: a baseline state and a measure of deviation from this baseline state. We argue that some of these incentives arise from the choice of baseline, and others arise from the choice of deviation measure. We introduce a new variant of the stepwise inaction baseline and a new deviation measure based on relative reachability of states. The combination of these design choices avoids the given undesirable incentives, while simpler baselines and the unreachability measure fail. We demonstrate this empirically by comparing different combinations of baseline and deviation measure choices on a set of gridworld experiments designed to illustrate possible bad incentives.},
  comment    = {RL Project Bachelor Thesis - Alex Roucka

Goal: RL agents that avoid causing unnecessary disruptions to their environment.

Idea: Use relative reachabiliyt from a baseline state as measure of disruption to the environment.

Gridworld Experiments},
  copyright  = {arXiv.org perpetual, non-exclusive license},
  doi        = {10.48550/ARXIV.1806.01186},
  groups     = {Alex Roucka},
  keywords   = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher  = {arXiv},
  readstatus = {read},
  url        = {https://arxiv.org/abs/1806.01186},
}

@InProceedings{2020_Turner_InProceedingsa,
  author         = {Alexander Matt Turner and Dylan Hadfield-Menell and Prasad Tadepalli},
  booktitle      = {Proceedings of the {AAAI}/{ACM} Conference on {AI}, Ethics, and Society},
  title          = {{C}onservative {A}gency via {A}ttainable {U}tility {P}reservation},
  year           = {2020},
  month          = {feb},
  publisher      = {{ACM}},
  abstract       = {Reward functions are easy to misspecify; although designers can make corrections after observing mistakes, an agent pursuing a misspecified reward function can irreversibly change the state of its environment. If that change precludes optimization of the correctly specified reward function, then correction is futile. For example, a robotic factory assistant could break expensive equipment due to a reward misspecification; even if the designers immediately correct the reward function, the damage is done. To mitigate this risk, we introduce an approach that balances optimization of the primary reward function with preservation of the ability to optimize auxiliary reward functions. Surprisingly, even when the auxiliary reward functions are randomly generated and therefore uninformative about the correctly specified reward function, this approach induces conservative, effective behavior.},
  comment        = {RL Project Bachelor Thesis - Alex Roucka

Implementations in aup.py and model_free_agent_py in "Attainable Utility Preservation" (https://github.com/alexander-turner/attainable-utility-preservation).



Improvements over this approaches in "Penalizing side effects using stepwise relative reachability" by Krakovna et al.},
  doi            = {10.1145/3375627.3375851},
  groups         = {Alex Roucka},
  qualityassured = {qualityAssured},
  readstatus     = {read},
  url            = {https://dl.acm.org/doi/abs/10.1145/3375627.3375851?casa_token=TOj2-yjPZYEAAAAA:4BKWRa1IBaYiDlTDq_ykSQ48wH0sMMHfzWd_3nN4EF7fqKF9iS7XYAXVkJV_WIpWtoC9wpRiFy4lHw},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: fileDirectory:/home/fabrice/Documents/library/papers;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:Analysis\;0\;1\;0x0000ffff\;MATH_INTEGRAL_BOX\;\;;
1 StaticGroup:Graphtheory\;0\;1\;0x008000ff\;GRAPHQL\;\;;
1 StaticGroup:MachineLearning\;0\;1\;0xffff00ff\;ROBOT_EXCITED_OUTLINE\;\;;
2 StaticGroup:ClusteringAlgorithms\;0\;1\;0xe64d4dff\;UNGROUP\;\;;
2 StaticGroup:ConvolutionNetworks\;0\;1\;0xff9966ff\;LAYERS_TRIPLE_OUTLINE\;\;;
2 StaticGroup:GraphKernels\;0\;1\;0x4d804dff\;GRAPH_OUTLINE\;\;;
2 StaticGroup:ReinforcementLearning\;0\;1\;0x808000ff\;ROBOT\;\;;
2 StaticGroup:SupportVectorMachines\;0\;0\;0xe6b34dff\;AB_TESTING\;\;;
1 StaticGroup:Projects\;0\;1\;0xffffffff\;ACCOUNT_GROUP\;Subgroups based on Projects\;;
2 StaticGroup:Alex Roucka\;0\;1\;0xffffffff\;\;His Bachelor Thesis based on AI Gridworlds, Reinforcement Learning, Q Learning, Relative Reachability and Attainable Utitlity Preservation\;;
}

@Comment{jabref-meta: saveActions:disabled;
all-text-fields[identity]
date[normalize_date]
month[normalize_month]
pages[normalize_page_numbers]
;}
